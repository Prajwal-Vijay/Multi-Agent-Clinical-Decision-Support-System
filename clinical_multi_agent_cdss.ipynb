{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prajwal-Vijay/Multi-Agent-Clinical-Decision-Support-System/blob/main/clinical_multi_agent_cdss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "984c5028",
      "metadata": {
        "id": "984c5028"
      },
      "source": [
        "\n",
        "# Multi‑Agent Clinical Decision Support System (CDSS)\n",
        "\n",
        "**Spec-compliant build** following the provided *Clinical Agents Outline* and *Task 3* requirements:\n",
        "- Three agents: **Clinical QA**, **Triage**, **Diagnosis**\n",
        "- **Hybrid retrieval** (BM25 + FAISS) with **Reciprocal Rank Fusion (RRF)** and cross‑encoder re‑ranking\n",
        "- **MCP** (Model Context Protocol) compliant tools for EHR access and clinical calculations\n",
        "- Domain adaptation (**DAPT**) and task‑specific fine‑tuning with **LoRA**\n",
        "- End‑to‑end orchestration, JSONL outputs, and evaluation scaffolding\n",
        "\n",
        "> ⚠️ **Educational / research use only**. This system operates on **synthetic Synthea** EHRs and is **not a medical device**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d46ca4",
      "metadata": {
        "id": "82d46ca4"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cebf0459",
      "metadata": {
        "id": "cebf0459"
      },
      "outputs": [],
      "source": [
        "\n",
        "# If running on a fresh environment, uncomment installs.\n",
        "%pip install -q pandas numpy scikit-learn pyarrow tqdm tabulate\n",
        "%pip install -q rank-bm25 faiss-cpu transformers accelerate peft bitsandbytes sentencepiece\n",
        "%pip install -q evaluate datasets jsonlines pydantic pydantic-settings\n",
        "%pip install -q loguru rich langchain\n",
        "%pip install -q mcp python-json-logger\n",
        "%pip install -q sacremoses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b148f9c2",
      "metadata": {
        "id": "b148f9c2"
      },
      "source": [
        "## 2. Configuration & Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dRICiLOl6SkG",
      "metadata": {
        "id": "dRICiLOl6SkG"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class RunConfig:\n",
        "    seed:int = 42\n",
        "    device:str = \"cuda\"   # \"cuda\", \"cpu\", or \"auto\"\n",
        "    use_int8:bool = True  # bitsandbytes for efficiency\n",
        "    embed_model:str = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "    cross_encoder:str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"  # replace with clinical cross-encoder if available\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.05\n",
        "\n",
        "CFG = RunConfig()\n",
        "print(CFG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5300017b",
      "metadata": {
        "id": "5300017b"
      },
      "source": [
        "## 3. Download & Load Synthea Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fce5d6d",
      "metadata": {
        "id": "0fce5d6d"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "DATA = Path(\"data\")\n",
        "DATA.mkdir(exist_ok=True)\n",
        "\n",
        "# uploaded file path\n",
        "local_zip = \"/content/synthea_sample_data_csv_apr2020.zip\"\n",
        "\n",
        "# extract\n",
        "with zipfile.ZipFile(local_zip, \"r\") as zf:\n",
        "    zf.extractall(DATA / \"csv\")\n",
        "\n",
        "CSV = DATA / \"csv\" / \"csv\"\n",
        "\n",
        "# load CSVs\n",
        "def load_csv(name):\n",
        "    return pd.read_csv(CSV / f\"{name}.csv\")\n",
        "\n",
        "patients = load_csv(\"patients\")\n",
        "encounters = load_csv(\"encounters\")\n",
        "observations = load_csv(\"observations\")\n",
        "conditions = load_csv(\"conditions\")\n",
        "medications = load_csv(\"medications\")\n",
        "procedures = load_csv(\"procedures\")\n",
        "\n",
        "patients.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24397682",
      "metadata": {
        "id": "24397682"
      },
      "source": [
        "## 4. Data Normalization & Joins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2641c497",
      "metadata": {
        "id": "2641c497"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Goes through each of the LOINC and ICD10 codes and normalizes them, by stripping their\n",
        "# ends and uppercasing them.\n",
        "def normalize_loinc(loinc:str):\n",
        "    if pd.isna(loinc):\n",
        "        return None\n",
        "    return str(loinc).strip().upper()\n",
        "\n",
        "def normalize_icd10(code:str):\n",
        "    if pd.isna(code):\n",
        "        return None\n",
        "    return str(code).strip().upper()\n",
        "\n",
        "observations[\"LOINC\"] = observations[\"CODE\"].apply(normalize_loinc)\n",
        "conditions[\"ICD10\"] = conditions[\"CODE\"].apply(normalize_icd10)\n",
        "\n",
        "# Build encounter-level keys for citation anchoring\n",
        "# These keys are going to be unique!\n",
        "def case_id(patient_id, encounter_id):\n",
        "    return f\"{patient_id}_{encounter_id}\"\n",
        "\n",
        "# Applying case ids to each of the tables.\n",
        "encounters[\"case_id\"] = encounters.apply(lambda r: case_id(r[\"PATIENT\"], r[\"Id\"]), axis=1)\n",
        "observations[\"case_id\"] = observations.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "conditions[\"case_id\"] = conditions.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "medications[\"case_id\"] = medications.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "procedures[\"case_id\"] = procedures.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "\n",
        "# Number of rows in each of the tables.\n",
        "print(\"Rows:\", {\n",
        "    \"patients\": len(patients), \"encounters\": len(encounters),\n",
        "    \"observations\": len(observations), \"conditions\": len(conditions),\n",
        "    \"medications\": len(medications), \"procedures\": len(procedures)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b55b3f7",
      "metadata": {
        "id": "0b55b3f7"
      },
      "source": [
        "## 5. Minimal Reference Ranges (Demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3341501d",
      "metadata": {
        "id": "3341501d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "OUTPUT = Path(\"outputs\")\n",
        "OUTPUT.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "REF_RANGES_FILE = OUTPUT / \"ref_ranges.json\"\n",
        "\n",
        "ref_ranges = {\n",
        "    \"8480-6\": {\"name\": \"Systolic BP\", \"units\": \"mmHg\", \"low\": 90, \"high\": 120},\n",
        "    \"8462-4\": {\"name\": \"Diastolic BP\", \"units\": \"mmHg\", \"low\": 60, \"high\": 80},\n",
        "    \"8867-4\": {\"name\": \"Heart rate\", \"units\": \"bpm\", \"low\": 60, \"high\": 100},\n",
        "    \"8310-5\": {\"name\": \"Body temperature\", \"units\": \"C\", \"low\": 36.1, \"high\": 37.2},\n",
        "    \"9279-1\": {\"name\": \"Respiratory rate\", \"units\": \"breaths/min\", \"low\": 12, \"high\": 20},\n",
        "    \"718-7\":  {\"name\": \"Hemoglobin\", \"units\": \"g/dL\", \"low\": 12, \"high\": 17.5},\n",
        "    \"2160-0\": {\"name\": \"Creatinine\", \"units\": \"mg/dL\", \"low\": 0.6, \"high\": 1.3}\n",
        "}\n",
        "REF_RANGES_FILE.write_text(json.dumps(ref_ranges, indent=2))\n",
        "print(\"Saved:\", REF_RANGES_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9b497b8",
      "metadata": {
        "id": "a9b497b8"
      },
      "source": [
        "## 6. Evidence Snippet Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368247d0",
      "metadata": {
        "id": "368247d0"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import json\n",
        "# Essentially we are converting all these structured data into text snippets.\n",
        "# Takes a row from the o  bservation table and creates a snippet for it.\n",
        "def make_obs_snippet(row, ref_ranges_map):\n",
        "    loinc = row.get(\"LOINC\")\n",
        "    value, unit = row.get(\"VALUE\"), row.get(\"UNITS\")\n",
        "    ts = row.get(\"DATE\")\n",
        "    meta = f\"obs:{row['PATIENT']}:{row['ENCOUNTER']}:{loinc}:{ts}\"\n",
        "    interp = None\n",
        "    if loinc in ref_ranges_map and pd.notna(value):\n",
        "        rr = ref_ranges_map[loinc]\n",
        "        try:\n",
        "            v = float(value)\n",
        "            if v < rr[\"low\"]:\n",
        "                interp = \"low\"\n",
        "            elif v > rr[\"high\"]:\n",
        "                interp = \"high\"\n",
        "            else:\n",
        "                interp = \"normal\"\n",
        "        except:\n",
        "            pass\n",
        "    text = f\"[{meta}] LOINC {loinc} value {value} {unit} on {ts}. Interpretation: {interp or 'unknown'}.\"\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"type\": \"observation\",\n",
        "        \"patient\": row[\"PATIENT\"],\n",
        "        \"encounter\": row[\"ENCOUNTER\"],\n",
        "        \"loinc\": loinc,\n",
        "        \"timestamp\": ts,\n",
        "        \"meta\": meta\n",
        "    }\n",
        "\n",
        "# Takes a row from the condition table and makes a snippet for it.\n",
        "def make_condition_snippet(row):\n",
        "    meta = f\"cond:{row['PATIENT']}:{row['ENCOUNTER']}:{row['ICD10']}:{row.get('START','')}\"\n",
        "    text = f\"[{meta}] ICD-10 {row['ICD10']} condition {row.get('DESCRIPTION','')} status {row.get('STATUS','')}.\"\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"type\": \"condition\",\n",
        "        \"patient\": row[\"PATIENT\"],\n",
        "        \"encounter\": row[\"ENCOUNTER\"],\n",
        "        \"icd10\": row[\"ICD10\"],\n",
        "        \"timestamp\": row.get(\"START\",\"\"),\n",
        "        \"meta\": meta\n",
        "    }\n",
        "\n",
        "# Medications table and snippets for that.\n",
        "def make_med_snippet(row):\n",
        "    meta = f\"med:{row['PATIENT']}:{row['ENCOUNTER']}:{row.get('CODE','')}:{row.get('START','')}\"\n",
        "    text = f\"[{meta}] Medication {row.get('DESCRIPTION','')} {row.get('REASONDESCRIPTION','')} dose {row.get('DOSE','')}.\"\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"type\": \"medication\",\n",
        "        \"patient\": row[\"PATIENT\"],\n",
        "        \"encounter\": row[\"ENCOUNTER\"],\n",
        "        \"code\": row.get(\"CODE\",\"\"),\n",
        "        \"timestamp\": row.get(\"START\",\"\"),\n",
        "        \"meta\": meta\n",
        "    }\n",
        "\n",
        "# Build corpus\n",
        "ref_map = json.loads(REF_RANGES_FILE.read_text())\n",
        "snippets = []\n",
        "for _, r in observations.iterrows():\n",
        "    snippets.append(make_obs_snippet(r, ref_map))\n",
        "for _, r in conditions.iterrows():\n",
        "    if pd.notna(r.get(\"ICD10\")):\n",
        "        snippets.append(make_condition_snippet(r))\n",
        "for _, r in medications.iterrows():\n",
        "    snippets.append(make_med_snippet(r))\n",
        "\n",
        "import pandas as pd\n",
        "corpus_df = pd.DataFrame(snippets)\n",
        "corpus_df.head()\n",
        "# Corpus dataframe is a dataframe of all observations, conditions, medications, essentailly a nice way to store all the info.\n",
        "\n",
        "# Why was it built the way it is built?\n",
        "# It is searchable, explainable, citable and a good evidence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd095ecf",
      "metadata": {
        "id": "fd095ecf"
      },
      "source": [
        "## 7. DAPT & LoRA Fine‑tuning (Scaffolding)\n",
        "\n",
        "Up and until this part everything was just zero shot or frozen-model inference.\n",
        "\n",
        "Here only we use the corpus etc and continued pretraining of the Clinical Bert model. This is followed by fine-tuning task heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b48c5804",
      "metadata": {
        "id": "b48c5804"
      },
      "outputs": [],
      "source": [
        "# This is a scaffold to continue pretraining (DAPT) on generated evidence snippets\n",
        "# and optionally fine-tune task heads. Adjust for your compute and data split.\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from pathlib import Path\n",
        "\n",
        "# Define BASE path (assuming it should be the current working directory or similar)\n",
        "BASE = Path(\".\")\n",
        "\n",
        "evidence_texts = corpus_df[\"text\"].tolist()[:20000]  # subset for demo\n",
        "ds = Dataset.from_dict({\"text\": evidence_texts})\n",
        "tok = AutoTokenizer.from_pretrained(CFG.embed_model)\n",
        "\n",
        "def tok_fn(batch):\n",
        "    return tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "tok_ds = ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "mlm_model = AutoModelForMaskedLM.from_pretrained(CFG.embed_model)\n",
        "peft_cfg = LoraConfig(r=CFG.lora_r, lora_alpha=CFG.lora_alpha, lora_dropout=CFG.lora_dropout, target_modules=[\"query\",\"value\",\"key\",\"dense\"])\n",
        "mlm_model = get_peft_model(mlm_model, peft_cfg)\n",
        "\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tok, mlm_probability=0.15)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=str(BASE / \"ckpts\" / \"dapt\"),\n",
        "    per_device_train_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=50,\n",
        "    save_steps=200,\n",
        "    report_to=[],\n",
        ")\n",
        "trainer = Trainer(model=mlm_model, args=args, train_dataset=tok_ds, data_collator=collator)\n",
        "trainer.train()\n",
        "mlm_model.save_pretrained(BASE / \"ckpts\" / \"dapt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f71582e",
      "metadata": {
        "id": "0f71582e"
      },
      "source": [
        "## 7. Hybrid Retrieval (BM25 + FAISS) with RRF\n",
        "\n",
        "BM25 is keyword based prediction, so it is going to give you answers where exact words match. Excellent for precise queries but misses semantic meaning.\n",
        "\n",
        "FAISS is for semantic similarity matching, it converts queries into high dimensional vectors and using embeddings it finds the closest matches. But it is prone to give highly irrelevant results.\n",
        "\n",
        "A combination of the two is the best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QsI0hDAG10Qk",
      "metadata": {
        "id": "QsI0hDAG10Qk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # should be True\n",
        "print(CFG.device)                 # should be \"cuda\" if available\n",
        "CFG.embed_model = str(BASE / \"ckpts\" / \"dapt\" / \"checkpoint-800\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5b5f50",
      "metadata": {
        "id": "1a5b5f50"
      },
      "outputs": [],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import re\n",
        "\n",
        "# Sample the corpus_df *before* creating the BM25 and FAISS indices\n",
        "# corpus_df = corpus_df.sample(5000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "tok = lambda s: [w for w in re.findall(r\"[A-Za-z0-9_.:-]+\", str(s).lower()) if w not in ENGLISH_STOP_WORDS]\n",
        "bm25 = BM25Okapi(corpus_df[\"text\"].apply(tok).tolist()) # Used to create a embedding that can be used for keyword based retreival.\n",
        "\n",
        "# Dense embeddings (FAISS) setup\n",
        "import numpy as np\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.embed_model)\n",
        "embed_model = AutoModel.from_pretrained(CFG.embed_model)\n",
        "\n",
        "# Commenting out LoRA configuration for the embedding model\n",
        "from peft import LoraConfig, get_peft_model\n",
        "peft_cfg = LoraConfig(r=CFG.lora_r, lora_alpha=CFG.lora_alpha, lora_dropout=CFG.lora_dropout, target_modules=[\"query\",\"value\",\"key\",\"dense\"])\n",
        "embed_model = get_peft_model(embed_model, peft_cfg)\n",
        "\n",
        "\n",
        "def mean_pool(last_hidden_state, attention_mask):\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-9)\n",
        "\n",
        "def encode_texts(texts, batch=64):\n",
        "    from torch import no_grad\n",
        "    import torch\n",
        "    embs = []\n",
        "    for i in range(0, len(texts), batch):\n",
        "        b = texts[i:i+batch]\n",
        "        inputs = tokenizer(b, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "        if CFG.device == \"auto\":\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            device = CFG.device\n",
        "        inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "        embed_model.to(device)\n",
        "        with no_grad():\n",
        "            out = embed_model(**inputs)\n",
        "            pooled = mean_pool(out.last_hidden_state, inputs[\"attention_mask\"])\n",
        "            embs.append(pooled.detach().cpu().numpy().astype(\"float32\"))\n",
        "    return np.vstack(embs)\n",
        "\n",
        "dense_embeddings = encode_texts(corpus_df[\"text\"].tolist(), batch=128)\n",
        "\n",
        "# Add print statements to inspect embeddings\n",
        "print(\"Shape of dense_embeddings:\", dense_embeddings.shape)\n",
        "print(\"Sample of dense_embeddings:\", dense_embeddings[:2])\n",
        "\n",
        "\n",
        "index = faiss.IndexFlatIP(dense_embeddings.shape[1])\n",
        "faiss.normalize_L2(dense_embeddings)\n",
        "index.add(dense_embeddings)\n",
        "\n",
        "def search_hybrid(query, top_k=50, rrf_k=60):\n",
        "    # BM25\n",
        "    bm_scores = bm25.get_scores(tok(query))\n",
        "    bm_top = np.argsort(-bm_scores)[:top_k]\n",
        "    # Dense\n",
        "    q_emb = encode_texts([query])\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    dense_top = I[0]\n",
        "\n",
        "    # RRF\n",
        "    # Rank positions\n",
        "    ranks = {}\n",
        "    for rank, idx in enumerate(bm_top, 1):\n",
        "        ranks.setdefault(idx, {})[\"bm25\"] = rank\n",
        "    for rank, idx in enumerate(dense_top, 1):\n",
        "        ranks.setdefault(idx, {})[\"dense\"] = rank\n",
        "    rrf_scores = {}\n",
        "    for idx, rks in ranks.items():\n",
        "        s = 0.0\n",
        "        if \"bm25\" in rks:  s += 1.0/(rrf_k + rks[\"bm25\"])\n",
        "        if \"dense\" in rks: s += 1.0/(rrf_k + rks[\"dense\"])\n",
        "        rrf_scores[idx] = s\n",
        "    ranked = sorted(rrf_scores.items(), key=lambda x: -x[1])[:top_k]\n",
        "    return [(int(i), float(s)) for i,s in ranked]\n",
        "\n",
        "# Simple cross-encoder rerank (placeholder: adds small weight to dense similarity)\n",
        "def rerank_with_cross_encoder(query, results, alpha=0.1):\n",
        "    # In production: load a clinical cross-encoder and score pairs (query, text).\n",
        "    # Here we nudge by dense proximity proxy carried in rrf score.\n",
        "    return sorted(results, key=lambda x: -x[1])  # already sorted"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faiss.write_index(index, \"faiss_index.index\")"
      ],
      "metadata": {
        "id": "lhJS2RKMOJX9"
      },
      "id": "lhJS2RKMOJX9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"bm25_index.pkl\", \"wb\") as f:\n",
        "  pickle.dump(bm25, f)"
      ],
      "metadata": {
        "id": "wgBuDWrwOz5D"
      },
      "id": "wgBuDWrwOz5D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "rdASus9ux7dD",
      "metadata": {
        "id": "rdASus9ux7dD"
      },
      "source": [
        "Till here Retreival part was implemented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57b30f98",
      "metadata": {
        "id": "57b30f98"
      },
      "source": [
        "## 8. MCP Tools (EHR & Clinical Calculators)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5025cef6",
      "metadata": {
        "id": "5025cef6"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field, ValidationError\n",
        "from typing import List, Optional, Literal, Dict, Any\n",
        "from datetime import datetime\n",
        "import math, logging, uuid\n",
        "\n",
        "# In this section we build schema validated tools/functions which the agents can call to\n",
        "# Access EHR data, Run clinical calculators, and audit all the usage of tokens\n",
        "LOGS = \"log\"\n",
        "logging.basicConfig(filename=str(f\"{LOGS} / audit.log\"), level=logging.INFO)\n",
        "\n",
        "class SearchEvidenceRequest(BaseModel):\n",
        "    patient_id: Optional[str] = None\n",
        "    query: str\n",
        "    data_types: Optional[List[Literal[\"observation\",\"condition\",\"medication\"]]] = None\n",
        "    top_k: int = 20\n",
        "\n",
        "class LabRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    loinc_codes: Optional[List[str]] = None\n",
        "    hours_back: Optional[int] = None\n",
        "\n",
        "class VitalsRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    vital_types: Optional[List[str]] = None\n",
        "    hours_back: Optional[int] = None\n",
        "\n",
        "class ConditionsRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    active_only: bool = True\n",
        "\n",
        "class MedsRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    encounter_id: Optional[str] = None\n",
        "\n",
        "# Logs every tool call\n",
        "def audit(event:str, payload:Dict[str,Any]):\n",
        "    logging.info(json.dumps({\n",
        "        \"ts\": datetime.utcnow().isoformat(),\n",
        "        \"event\": event,\n",
        "        \"payload\": payload\n",
        "    }))\n",
        "\n",
        "# EHR search\n",
        "#\n",
        "def ehr_search_evidence(req: SearchEvidenceRequest):\n",
        "    try:\n",
        "        req = SearchEvidenceRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "\n",
        "    # Perform hy  brid search to get initial results\n",
        "    # Increase top_k to retrieve a larger set before filtering by patient_id\n",
        "    initial_results = rerank_with_cross_encoder(req.query, search_hybrid(req.query, top_k=200))\n",
        "\n",
        "    hits = []\n",
        "    for idx, score in initial_results:\n",
        "        row = corpus_df.iloc[idx]\n",
        "        # Apply patient_id and data_types filtering after initial search\n",
        "        if req.patient_id and row[\"patient\"] != req.patient_id:\n",
        "            continue\n",
        "        if req.data_types and row[\"type\"] not in req.data_types:\n",
        "            continue\n",
        "        hits.append({\"text\": row[\"text\"], \"meta\": row[\"meta\"], \"score\": score, \"type\": row[\"type\"]})\n",
        "\n",
        "    # Limit the final number of hits\n",
        "    hits = hits[:req.top_k]\n",
        "\n",
        "    audit(\"ehr.search_evidence\", {\"query\": req.query, \"n\": len(hits)})\n",
        "    return hits\n",
        "\n",
        "\n",
        "def ehr_get_labs(req: LabRequest):\n",
        "    try:\n",
        "        req = LabRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    df = observations[observations[\"PATIENT\"] == req.patient_id]\n",
        "    if req.loinc_codes:\n",
        "        df = df[df[\"LOINC\"].isin(req.loinc_codes)]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "def ehr_get_vitals(req: VitalsRequest):\n",
        "    try:\n",
        "        req = VitalsRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    vital_codes = [\"8480-6\",\"8462-4\",\"8867-4\",\"8310-5\",\"9279-1\"]\n",
        "    df = observations[(observations[\"PATIENT\"] == req.patient_id) & (observations[\"LOINC\"].isin(vital_codes))]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "def ehr_get_conditions(req: ConditionsRequest):\n",
        "    try:\n",
        "        req = ConditionsRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    df = conditions[conditions[\"PATIENT\"] == req.patient_id]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "def ehr_get_medications(req: MedsRequest):\n",
        "    try:\n",
        "        req = MedsRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    df = medications[medications[\"PATIENT\"] == req.patient_id]\n",
        "    if req.encounter_id:\n",
        "        df = df[df[\"ENCOUNTER\"] == req.encounter_id]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "# Clinical calculators\n",
        "def calc_qsofa(respiratory_rate, systolic_bp, gcs_score):\n",
        "    score = 0\n",
        "    score += 1 if respiratory_rate is not None and respiratory_rate >= 22 else 0\n",
        "    score += 1 if systolic_bp is not None and systolic_bp <= 100 else 0\n",
        "    score += 1 if gcs_score is not None and gcs_score < 15 else 0\n",
        "    return {\"qSOFA\": score}\n",
        "\n",
        "def calc_egfr(creatinine, age, sex, race=\"non-black\"):\n",
        "    # CKD-EPI 2009 (simplified; for demo only)\n",
        "    kappa = 0.7 if sex.lower().startswith(\"f\") else 0.9\n",
        "    alpha = -0.329 if sex.lower().startswith(\"f\") else -0.411\n",
        "    min_scr = min(creatinine/kappa, 1)\n",
        "    max_scr = max(creatinine/kappa, 1)\n",
        "    egfr = 141 * (min_scr**alpha) * (max_scr**(-1.209)) * (0.993**age)\n",
        "    if sex.lower().startswith(\"f\"): egfr *= 1.018\n",
        "    if race.lower() == \"black\": egfr *= 1.159\n",
        "    return {\"eGFR\": egfr}\n",
        "\n",
        "def calc_lab_interpretation(code, value, units, age=None, sex=None):\n",
        "    rm = json.loads(REF_RANGES_FILE.read_text())\n",
        "    status = \"unknown\"\n",
        "    if code in rm:\n",
        "        low, high = rm[code][\"low\"], rm[code][\"high\"]\n",
        "        try:\n",
        "            v = float(value)\n",
        "            status = \"low\" if v < low else (\"high\" if v > high else \"normal\")\n",
        "        except:\n",
        "            status = \"unknown\"\n",
        "    return {\"interpretation\": status}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01726381",
      "metadata": {
        "id": "01726381"
      },
      "source": [
        "## 9. Agents (Clinical QA, Triage, Diagnosis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de29d438",
      "metadata": {
        "id": "de29d438"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load BioGPT model (causal LM)\n",
        "biogpt_model_name = \"microsoft/BioGPT-Large\"\n",
        "biogpt_tokenizer = AutoTokenizer.from_pretrained(biogpt_model_name)\n",
        "biogpt_model = AutoModelForCausalLM.from_pretrained(\n",
        "    biogpt_model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# WE are using local models instead of APIs for ease of reproducibility\n",
        "class ClinicalQAAgentRAG:\n",
        "    def answer(self, patient_id:str, question:str, triage_flags: List[Dict[str, Any]], top_k:int=5, max_new_tokens:int=200):\n",
        "        # 1) Retrieve top-k evidence\n",
        "        # Construct a more specific query based on triage flags if available\n",
        "        if triage_flags:\n",
        "            flag_queries = [f\"{flag['interpretation']} {flag['test_code']}\" for flag in triage_flags]\n",
        "            # Combine original question with flag information for a more targeted query\n",
        "            targeted_query = f\"{question} based on abnormal findings: {', '.join(flag_queries)}\"\n",
        "        else:\n",
        "            targeted_query = question\n",
        "\n",
        "        hits = ehr_search_evidence({\"patient_id\": patient_id, \"query\": targeted_query, \"top_k\": top_k})\n",
        "        top_snippets = hits[:top_k]\n",
        "\n",
        "        # 2) Build prompt for BioGPT\n",
        "        evidence_text = \"\\n\".join([f\"- {h['text']}\" for h in top_snippets])\n",
        "        print(evidence_text)\n",
        "        prompt = (\n",
        "            f\"Question: {question}\\n\\n\"\n",
        "            f\"Patient evidence:\\n{evidence_text}\\n\\n\"\n",
        "            f\"Answer the question using only the evidence above. \"\n",
        "            f\"Include the citation meta IDs (inside brackets, e.g., [obs:...]).\\n\\n\"\n",
        "            f\"Answer:\"\n",
        "        )\n",
        "\n",
        "        # 3) Generate with BioGPT\n",
        "        inputs = biogpt_tokenizer(prompt, return_tensors=\"pt\").to(biogpt_model.device)\n",
        "        outputs = biogpt_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        answer = biogpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # 4) Package results\n",
        "        citations = [h[\"meta\"] for h in top_snippets]\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"citations\": citations,\n",
        "            \"hits\": top_snippets\n",
        "        }\n",
        "\n",
        "class TriageAgent:\n",
        "    def analyze(self, patient_id:str):\n",
        "        labs = ehr_get_labs({\"patient_id\": patient_id})\n",
        "        vitals = ehr_get_vitals({\"patient_id\": patient_id})\n",
        "        flags = []\n",
        "        for row in labs + vitals:\n",
        "            code = row.get(\"LOINC\")\n",
        "            val = row.get(\"VALUE\")\n",
        "            units = row.get(\"UNITS\")\n",
        "            interp = calc_lab_interpretation(code, val, units)\n",
        "            if interp[\"interpretation\"] in {\"low\",\"high\"}:\n",
        "                flags.append({\n",
        "                    \"test_code\": code, \"value\": val, \"interpretation\": interp[\"interpretation\"],\n",
        "                    \"abnormal\": True, \"meta\": f\"obs:{row['PATIENT']}:{row['ENCOUNTER']}:{code}:{row.get('DATE','')}\"\n",
        "                })\n",
        "        # qSOFA demo: fetch last vitals\n",
        "        def last_value(code):\n",
        "            rows = [r for r in vitals if r.get(\"LOINC\")==code and pd.notna(r.get(\"VALUE\"))]\n",
        "            if not rows: return None\n",
        "            try: return float(rows[-1][\"VALUE\"])\n",
        "            except: return None\n",
        "        rr = last_value(\"9279-1\")\n",
        "        sbp = last_value(\"8480-6\")\n",
        "        gcs = 15  # Synthea lacks GCS; assume normal for demo\n",
        "        qsofa = calc_qsofa(rr, sbp, gcs)\n",
        "        # qSOFA is a score that indicates risk.\n",
        "        return {\"flags\": flags, \"scores\": {\"qSOFA\": qsofa[\"qSOFA\"]}}\n",
        "\n",
        "class DiagnosisAgent:\n",
        "    def predict(self, patient_id:str):\n",
        "        # Heuristic placeholder: collect active conditions and propose common ICD10 codes\n",
        "        conds = ehr_get_conditions({\"patient_id\": patient_id})\n",
        "        preds = list({c.get(\"ICD10\") for c in conds if c.get(\"ICD10\")})[:3]\n",
        "        confidences = [0.7 if i==0 else 0.5 for i in range(len(preds))]\n",
        "        evidence = [f\"cond:{c['PATIENT']}:{c['ENCOUNTER']}:{c.get('ICD10')}:{c.get('START','')}\" for c in conds[:5]]\n",
        "        return {\"predictions\": preds, \"confidences\": confidences, \"evidence\": evidence}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d40e1071",
      "metadata": {
        "id": "d40e1071"
      },
      "source": [
        "## 10. Orchestration (QA → Triage → Diagnosis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dfb77e",
      "metadata": {
        "id": "03dfb77e"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "# An Orchestrator is the controller of the multi agents, it calls the agents in the right order passes the right data and assembles the results in the right order. Used to\n",
        "# \"stich\" the agents in one pipeline.\n",
        "\n",
        "class Orchestrator:\n",
        "    def __init__(self):\n",
        "        self.qa = ClinicalQAAgentRAG()\n",
        "        self.triage = TriageAgent()\n",
        "        self.dx = DiagnosisAgent()\n",
        "\n",
        "    def run_case(self, patient_id:str, encounter_id:str=None, question:str=\"What are the key issues?\"):\n",
        "        case = encounter_id or f\"any\"\n",
        "        case_id = f\"{patient_id}_{case}\"\n",
        "        triage_out = self.triage.analyze(patient_id)\n",
        "        # Pass triage_flags to the QA agent\n",
        "        qa_out = self.qa.answer(patient_id, question, triage_flags=triage_out[\"flags\"])\n",
        "        dx_out = self.dx.predict(patient_id)\n",
        "\n",
        "        # Structured synthesis\n",
        "        report = {\n",
        "            \"case_id\": case_id,\n",
        "            \"question\": question,\n",
        "            \"qa\": qa_out,\n",
        "            \"triage\": triage_out,\n",
        "            \"diagnosis\": dx_out\n",
        "        }\n",
        "        return report\n",
        "\n",
        "orch = Orchestrator()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c0dace5",
      "metadata": {
        "id": "3c0dace5"
      },
      "source": [
        "## 11. Evaluation & Required JSONL Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe9ac2e",
      "metadata": {
        "id": "7fe9ac2e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import jsonlines\n",
        "\n",
        "def write_required_outputs(report, output_dir=OUTPUT):\n",
        "    output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # retrieval_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"retrieval_results.jsonl\", \"w\") as w:\n",
        "        for i, h in enumerate(report[\"qa\"][\"hits\"][:50]):\n",
        "            w.write({\n",
        "                \"query_id\": f\"Q001\",\n",
        "                \"patient_id\": report[\"case_id\"].split(\"_\")[0],\n",
        "                \"snippets\": [h[\"text\"]],\n",
        "                \"scores\": [h[\"score\"]]\n",
        "            })\n",
        "\n",
        "    # qa_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"qa_results.jsonl\", \"w\") as w:\n",
        "        w.write({\n",
        "            \"case_id\": report[\"case_id\"],\n",
        "            \"question\": report[\"question\"],\n",
        "            \"answer\": report[\"qa\"][\"answer\"],\n",
        "            \"citations\": report[\"qa\"][\"citations\"]\n",
        "        })\n",
        "\n",
        "    # triage_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"triage_results.jsonl\", \"w\") as w:\n",
        "        for flag in report[\"triage\"][\"flags\"]:\n",
        "            w.write({\n",
        "                \"case_id\": report[\"case_id\"],\n",
        "                \"test_code\": flag[\"test_code\"],\n",
        "                \"value\": flag[\"value\"],\n",
        "                \"interpretation\": flag[\"interpretation\"],\n",
        "                \"abnormal\": flag[\"abnormal\"]\n",
        "            })\n",
        "\n",
        "    # diagnosis_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"diagnosis_results.jsonl\", \"w\") as w:\n",
        "        w.write({\n",
        "            \"case_id\": report[\"case_id\"],\n",
        "            \"predictions\": report[\"diagnosis\"][\"predictions\"],\n",
        "            \"confidences\": report[\"diagnosis\"][\"confidences\"],\n",
        "            \"evidence\": report[\"diagnosis\"][\"evidence\"]\n",
        "        })\n",
        "\n",
        "    # system_metrics.json (placeholder)\n",
        "    metrics = {\n",
        "        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        \"n_evidence\": len(report[\"qa\"][\"hits\"]),\n",
        "        \"n_flags\": len(report[\"triage\"][\"flags\"]),\n",
        "        \"qSOFA\": report[\"triage\"][\"scores\"][\"qSOFA\"]\n",
        "    }\n",
        "    (output_dir / \"system_metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
        "    return [str(p) for p in (output_dir.iterdir()) if p.is_file()]\n",
        "\n",
        "# Demo run on the first patient\n",
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "report = orch.run_case(demo_patient, question=\"Possible causes of abnormal vitals and labs?\")\n",
        "files = write_required_outputs(report)\n",
        "print(report)\n",
        "files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9649505",
      "metadata": {
        "id": "a9649505"
      },
      "outputs": [],
      "source": [
        "# Find a patient with abnormal observations\n",
        "abnormal_observations = observations[observations['LOINC'].isin(ref_map.keys())]\n",
        "\n",
        "# Filter for observations outside the normal range\n",
        "def is_abnormal(row):\n",
        "    loinc = row.get(\"LOINC\")\n",
        "    value = row.get(\"VALUE\")\n",
        "    if loinc in ref_map and pd.notna(value):\n",
        "        rr = ref_map[loinc]\n",
        "        try:\n",
        "            v = float(value)\n",
        "            if v < rr[\"low\"] or v > rr[\"high\"]:\n",
        "                return True\n",
        "        except:\n",
        "            pass\n",
        "    return False\n",
        "\n",
        "abnormal_patients_df = abnormal_observations[abnormal_observations.apply(is_abnormal, axis=1)]\n",
        "\n",
        "if not abnormal_patients_df.empty:\n",
        "    new_demo_patient = abnormal_patients_df.iloc[0][\"PATIENT\"]\n",
        "    print(f\"Found a patient with abnormal observations: {new_demo_patient}\")\n",
        "    # Now run the orchestrator with the new patient ID\n",
        "    report = orch.run_case(new_demo_patient, question=\"What is the diagnosis inferred from vitals and labs?\")\n",
        "    files = write_required_outputs(report)\n",
        "    print(report)\n",
        "    display(files)\n",
        "else:\n",
        "    print(\"No patients with abnormal observations found in the corpus.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e85a62",
      "metadata": {
        "id": "06e85a62"
      },
      "outputs": [],
      "source": [
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "search_results = ehr_search_evidence({\"patient_id\": demo_patient, \"query\": \"Possible causes of abnormal vitals and labs?\", \"top_k\": 20})\n",
        "print(search_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b0634ff",
      "metadata": {
        "id": "4b0634ff"
      },
      "outputs": [],
      "source": [
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "search_results = ehr_search_evidence({\"patient_id\": demo_patient, \"query\": \"patient's blood pressure\", \"top_k\": 20})\n",
        "print(search_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cbd454",
      "metadata": {
        "id": "91cbd454"
      },
      "source": [
        "## 13. Safety, Validation & Disclaimers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9ce6ba",
      "metadata": {
        "id": "1c9ce6ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "def validate_inputs_or_raise(patient_id:str):\n",
        "    assert isinstance(patient_id, str) and len(patient_id)>0, \"Invalid patient_id\"\n",
        "\n",
        "def human_in_the_loop_required(conf: float, threshold: float = 0.8) -> bool:\n",
        "    return conf < threshold\n",
        "\n",
        "print(\"Safety helpers ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "395546f3",
      "metadata": {
        "id": "395546f3"
      },
      "source": [
        "## 14. Quickstart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d6f689",
      "metadata": {
        "id": "29d6f689"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\"\"\n",
        "1) Run Section 1 to install dependencies (if needed).\n",
        "2) Run Sections 2–6 to prepare data & evidence corpus.\n",
        "3) Run Section 7 to build hybrid indices.\n",
        "4) Run Sections 8–11 to enable MCP tools, agents, orchestration, and outputs.\n",
        "5) (Optional) Run Section 12 to experiment with DAPT/LoRA.\n",
        "Outputs are written to ./outputs in the required JSONL/JSON formats.\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feb5147e"
      },
      "source": [
        "# Final Testing and Analysis Cell\n",
        "\n",
        "import time\n",
        "import random\n",
        "import jsonlines\n",
        "from pathlib import Path\n",
        "\n",
        "# Define an output directory for this final test run\n",
        "TEST_OUTPUT_DIR = Path(\"test_outputs\")\n",
        "TEST_OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# --- Performance Analysis ---\n",
        "print(\"--- Performance Analysis ---\")\n",
        "num_runs = 10  # Number of times to run the orchestrator for performance testing\n",
        "total_time = 0\n",
        "\n",
        "# Get a list of patient IDs to use for testing\n",
        "test_patient_ids = patients[\"Id\"].tolist()\n",
        "if len(test_patient_ids) > num_runs:\n",
        "    test_patient_ids = random.sample(test_patient_ids, num_runs)\n",
        "else:\n",
        "    num_runs = len(test_patient_ids) # Adjust num_runs if fewer patients than requested\n",
        "\n",
        "for i in range(num_runs):\n",
        "    patient_id = test_patient_ids[i]\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        report = orch.run_case(patient_id, question=\"What are the main health concerns for this patient?\")\n",
        "        # Optionally write outputs for each run if needed for later analysis\n",
        "        # write_required_outputs(report, output_dir=TEST_OUTPUT_DIR / f\"run_{i}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during performance run {i} for patient {patient_id}: {e}\")\n",
        "        continue\n",
        "    end_time = time.time()\n",
        "    run_time = end_time - start_time\n",
        "    total_time += run_time\n",
        "    print(f\"Run {i+1} for patient {patient_id} took {run_time:.2f} seconds\")\n",
        "\n",
        "average_time = total_time / num_runs if num_runs > 0 else 0\n",
        "print(f\"\\nAverage time per case: {average_time:.2f} seconds\")\n",
        "\n",
        "# --- Error Case Testing ---\n",
        "print(\"\\n--- Error Case Testing ---\")\n",
        "\n",
        "# Test with an invalid patient ID\n",
        "print(\"\\nTesting with invalid patient ID:\")\n",
        "invalid_patient_id = \"invalid-patient-id-123\"\n",
        "try:\n",
        "    report = orch.run_case(invalid_patient_id, question=\"Should not work\")\n",
        "    print(\"Unexpected success with invalid patient ID.\")\n",
        "except Exception as e:\n",
        "    print(f\"Caught expected error for invalid patient ID: {e}\")\n",
        "\n",
        "# Test with an empty question\n",
        "print(\"\\nTesting with empty question:\")\n",
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "try:\n",
        "    report = orch.run_case(demo_patient, question=\"\")\n",
        "    print(\"Result for empty question:\", report[\"qa\"][\"answer\"])\n",
        "except Exception as e:\n",
        "    print(f\"Caught error for empty question: {e}\")\n",
        "\n",
        "\n",
        "# --- Ablation Studies (Conceptual - requires code modification) ---\n",
        "print(\"\\n--- Ablation Studies (Conceptual) ---\")\n",
        "print(\"Ablation studies would typically involve modifying the Orchestrator or agents\")\n",
        "print(\"to remove specific components (e.g., hybrid retrieval, RRF, specific tools)\")\n",
        "print(\"and then re-running the same test cases to compare performance.\")\n",
        "print(\"This requires code changes outside of this test cell.\")\n",
        "print(\"\\nFor example, to test the impact of hybrid retrieval, you would modify\")\n",
        "print(\"ehr_search_evidence to use *only* BM25 or *only* dense retrieval.\")\n",
        "print(\"Then, run the performance analysis again and compare results.\")\n",
        "\n",
        "# Example of how you *might* simulate an ablation (this requires modifying the orch instance)\n",
        "# Note: This is just illustrative. A proper ablation study would involve code changes elsewhere.\n",
        "# print(\"\\nIllustrative example: Simulating removing hybrid retrieval (requires code change)\")\n",
        "# original_search_fn = ehr_search_evidence\n",
        "# def simple_search_ablation(req: SearchEvidenceRequest):\n",
        "#     # Simulate only dense search (conceptual)\n",
        "#     print(\"Using simulated simple search (ablation)\")\n",
        "#     q_emb = encode_texts([req.query])\n",
        "#     faiss.normalize_L2(q_emb)\n",
        "#     D, I = index.search(q_emb, req.top_k)\n",
        "#     hits = []\n",
        "#     for i, score in zip(I[0], D[0]):\n",
        "#         row = corpus_df.iloc[i]\n",
        "#         if req.patient_id and row[\"patient\"] != req.patient_id:\n",
        "#              continue\n",
        "#         if req.data_types and row[\"type\"] not in req.data_types:\n",
        "#              continue\n",
        "#         hits.append({\"text\": row[\"text\"], \"meta\": row[\"meta\"], \"score\": float(score), \"type\": row[\"type\"]}) # Convert score to float\n",
        "#     return hits[:req.top_k]\n",
        "\n",
        "# # Temporarily replace the search function (requires direct modification of the module or class)\n",
        "# # This is complex and not recommended in a simple test cell.\n",
        "# # Instead, modify the Orchestrator class or the ehr_search_evidence function directly\n",
        "# # for a proper ablation study.\n",
        "# # orch.qa.ehr_search_evidence = simple_search_ablation # This line won't work directly\n",
        "\n",
        "print(\"\\nFinal testing complete.\")"
      ],
      "id": "feb5147e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}