{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "984c5028",
      "metadata": {
        "id": "984c5028"
      },
      "source": [
        "\n",
        "# Multi‑Agent Clinical Decision Support System (CDSS)\n",
        "\n",
        "**Spec-compliant build** following the provided *Clinical Agents Outline* and *Task 3* requirements:\n",
        "- Three agents: **Clinical QA**, **Triage**, **Diagnosis**\n",
        "- **Hybrid retrieval** (BM25 + FAISS) with **Reciprocal Rank Fusion (RRF)** and cross‑encoder re‑ranking\n",
        "- **MCP** (Model Context Protocol) compliant tools for EHR access and clinical calculations\n",
        "- Domain adaptation (**DAPT**) and task‑specific fine‑tuning with **LoRA**\n",
        "- End‑to‑end orchestration, JSONL outputs, and evaluation scaffolding\n",
        "\n",
        "> ⚠️ **Educational / research use only**. This system operates on **synthetic Synthea** EHRs and is **not a medical device**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d46ca4",
      "metadata": {
        "id": "82d46ca4"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cebf0459",
      "metadata": {
        "id": "cebf0459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab63516e-ae60-4e65-957d-b8edbb606474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "# If running on a fresh environment, uncomment installs.\n",
        "%pip install -q pandas numpy scikit-learn pyarrow tqdm tabulate\n",
        "%pip install -q rank-bm25 faiss-cpu transformers accelerate peft bitsandbytes sentencepiece\n",
        "%pip install -q evaluate datasets jsonlines pydantic pydantic-settings\n",
        "%pip install -q loguru rich langchain\n",
        "%pip install -q mcp python-json-logger\n",
        "%pip install -q sacremoses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b148f9c2",
      "metadata": {
        "id": "b148f9c2"
      },
      "source": [
        "## 2. Configuration & Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dRICiLOl6SkG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRICiLOl6SkG",
        "outputId": "d7ebfce6-6900-48cd-e2c3-a85e35ab6a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunConfig(seed=42, device='cuda', use_int8=True, embed_model='emilyalsentzer/Bio_ClinicalBERT', cross_encoder='cross-encoder/ms-marco-MiniLM-L-6-v2', lora_r=8, lora_alpha=16, lora_dropout=0.05)\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class RunConfig:\n",
        "    seed:int = 42\n",
        "    device:str = \"cuda\"   # \"cuda\", \"cpu\", or \"auto\"\n",
        "    use_int8:bool = True  # bitsandbytes for efficiency\n",
        "    embed_model:str = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "    cross_encoder:str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"  # replace with clinical cross-encoder if available\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.05\n",
        "\n",
        "CFG = RunConfig()\n",
        "print(CFG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5300017b",
      "metadata": {
        "id": "5300017b"
      },
      "source": [
        "## 3. Download & Load Synthea Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0fce5d6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "0fce5d6d",
        "outputId": "613a5f36-d95a-430c-e593-91a537df996f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Id   BIRTHDATE DEATHDATE          SSN  \\\n",
              "0  1d604da9-9a81-4ba9-80c2-de3375d59b40  1989-05-25       NaN  999-76-6866   \n",
              "1  034e9e3b-2def-4559-bb2a-7850888ae060  1983-11-14       NaN  999-73-5361   \n",
              "2  10339b10-3cd1-4ac3-ac13-ec26728cb592  1992-06-02       NaN  999-27-3385   \n",
              "3  8d4c4326-e9de-4f45-9a4c-f8c36bff89ae  1978-05-27       NaN  999-85-4926   \n",
              "4  f5dcd418-09fe-4a2f-baa0-3da800bd8c3a  1996-10-18       NaN  999-60-7372   \n",
              "\n",
              "     DRIVERS    PASSPORT PREFIX            FIRST           LAST SUFFIX  ...  \\\n",
              "0  S99984236  X19277260X    Mr.  José Eduardo181       Gómez206    NaN  ...   \n",
              "1  S99962402  X88275464X    Mr.          Milo271        Feil794    NaN  ...   \n",
              "2  S99972682  X73754411X    Mr.        Jayson808       Fadel536    NaN  ...   \n",
              "3  S99974448  X40915583X   Mrs.       Mariana775  Rutherford999    NaN  ...   \n",
              "4  S99915787  X86772962X    Mr.      Gregorio366         Auer97    NaN  ...   \n",
              "\n",
              "                         BIRTHPLACE                         ADDRESS  \\\n",
              "0  Marigot  Saint Andrew Parish  DM      427 Balistreri Way Unit 19   \n",
              "1        Danvers  Massachusetts  US        422 Farrell Path Unit 69   \n",
              "2    Springfield  Massachusetts  US       1056 Harris Lane Suite 70   \n",
              "3       Yarmouth  Massachusetts  US                  999 Kuhn Forge   \n",
              "4                Patras  Achaea  GR  1050 Lindgren Extension Apt 38   \n",
              "\n",
              "         CITY          STATE            COUNTY     ZIP        LAT        LON  \\\n",
              "0    Chicopee  Massachusetts    Hampden County  1013.0  42.228354 -72.562951   \n",
              "1  Somerville  Massachusetts  Middlesex County  2143.0  42.360697 -71.126531   \n",
              "2    Chicopee  Massachusetts    Hampden County  1020.0  42.181642 -72.608842   \n",
              "3      Lowell  Massachusetts  Middlesex County  1851.0  42.636143 -71.343255   \n",
              "4      Boston  Massachusetts    Suffolk County  2135.0  42.352434 -71.028610   \n",
              "\n",
              "  HEALTHCARE_EXPENSES HEALTHCARE_COVERAGE  \n",
              "0           271227.08             1334.88  \n",
              "1           793946.01             3204.49  \n",
              "2           574111.90             2606.40  \n",
              "3           935630.30             8756.19  \n",
              "4           598763.07             3772.20  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d92addc7-19c5-462b-bce6-1c08d9a47efb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>BIRTHDATE</th>\n",
              "      <th>DEATHDATE</th>\n",
              "      <th>SSN</th>\n",
              "      <th>DRIVERS</th>\n",
              "      <th>PASSPORT</th>\n",
              "      <th>PREFIX</th>\n",
              "      <th>FIRST</th>\n",
              "      <th>LAST</th>\n",
              "      <th>SUFFIX</th>\n",
              "      <th>...</th>\n",
              "      <th>BIRTHPLACE</th>\n",
              "      <th>ADDRESS</th>\n",
              "      <th>CITY</th>\n",
              "      <th>STATE</th>\n",
              "      <th>COUNTY</th>\n",
              "      <th>ZIP</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LON</th>\n",
              "      <th>HEALTHCARE_EXPENSES</th>\n",
              "      <th>HEALTHCARE_COVERAGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1d604da9-9a81-4ba9-80c2-de3375d59b40</td>\n",
              "      <td>1989-05-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>999-76-6866</td>\n",
              "      <td>S99984236</td>\n",
              "      <td>X19277260X</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>José Eduardo181</td>\n",
              "      <td>Gómez206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Marigot  Saint Andrew Parish  DM</td>\n",
              "      <td>427 Balistreri Way Unit 19</td>\n",
              "      <td>Chicopee</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>Hampden County</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>42.228354</td>\n",
              "      <td>-72.562951</td>\n",
              "      <td>271227.08</td>\n",
              "      <td>1334.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
              "      <td>1983-11-14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>999-73-5361</td>\n",
              "      <td>S99962402</td>\n",
              "      <td>X88275464X</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>Milo271</td>\n",
              "      <td>Feil794</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Danvers  Massachusetts  US</td>\n",
              "      <td>422 Farrell Path Unit 69</td>\n",
              "      <td>Somerville</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>Middlesex County</td>\n",
              "      <td>2143.0</td>\n",
              "      <td>42.360697</td>\n",
              "      <td>-71.126531</td>\n",
              "      <td>793946.01</td>\n",
              "      <td>3204.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10339b10-3cd1-4ac3-ac13-ec26728cb592</td>\n",
              "      <td>1992-06-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>999-27-3385</td>\n",
              "      <td>S99972682</td>\n",
              "      <td>X73754411X</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>Jayson808</td>\n",
              "      <td>Fadel536</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Springfield  Massachusetts  US</td>\n",
              "      <td>1056 Harris Lane Suite 70</td>\n",
              "      <td>Chicopee</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>Hampden County</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>42.181642</td>\n",
              "      <td>-72.608842</td>\n",
              "      <td>574111.90</td>\n",
              "      <td>2606.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8d4c4326-e9de-4f45-9a4c-f8c36bff89ae</td>\n",
              "      <td>1978-05-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>999-85-4926</td>\n",
              "      <td>S99974448</td>\n",
              "      <td>X40915583X</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>Mariana775</td>\n",
              "      <td>Rutherford999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Yarmouth  Massachusetts  US</td>\n",
              "      <td>999 Kuhn Forge</td>\n",
              "      <td>Lowell</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>Middlesex County</td>\n",
              "      <td>1851.0</td>\n",
              "      <td>42.636143</td>\n",
              "      <td>-71.343255</td>\n",
              "      <td>935630.30</td>\n",
              "      <td>8756.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f5dcd418-09fe-4a2f-baa0-3da800bd8c3a</td>\n",
              "      <td>1996-10-18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>999-60-7372</td>\n",
              "      <td>S99915787</td>\n",
              "      <td>X86772962X</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>Gregorio366</td>\n",
              "      <td>Auer97</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Patras  Achaea  GR</td>\n",
              "      <td>1050 Lindgren Extension Apt 38</td>\n",
              "      <td>Boston</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>Suffolk County</td>\n",
              "      <td>2135.0</td>\n",
              "      <td>42.352434</td>\n",
              "      <td>-71.028610</td>\n",
              "      <td>598763.07</td>\n",
              "      <td>3772.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d92addc7-19c5-462b-bce6-1c08d9a47efb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d92addc7-19c5-462b-bce6-1c08d9a47efb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d92addc7-19c5-462b-bce6-1c08d9a47efb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-296772f6-97f7-4e03-abba-bbc9e086814a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-296772f6-97f7-4e03-abba-bbc9e086814a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-296772f6-97f7-4e03-abba-bbc9e086814a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "patients"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "DATA = Path(\"data\")\n",
        "DATA.mkdir(exist_ok=True)\n",
        "\n",
        "# uploaded file path\n",
        "local_zip = \"/content/synthea_sample_data_csv_apr2020.zip\"\n",
        "\n",
        "# extract\n",
        "with zipfile.ZipFile(local_zip, \"r\") as zf:\n",
        "    zf.extractall(DATA / \"csv\")\n",
        "\n",
        "CSV = DATA / \"csv\" / \"csv\"\n",
        "\n",
        "# load CSVs\n",
        "def load_csv(name):\n",
        "    return pd.read_csv(CSV / f\"{name}.csv\")\n",
        "\n",
        "patients = load_csv(\"patients\")\n",
        "encounters = load_csv(\"encounters\")\n",
        "observations = load_csv(\"observations\")\n",
        "conditions = load_csv(\"conditions\")\n",
        "medications = load_csv(\"medications\")\n",
        "procedures = load_csv(\"procedures\")\n",
        "\n",
        "patients.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24397682",
      "metadata": {
        "id": "24397682"
      },
      "source": [
        "## 4. Data Normalization & Joins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2641c497",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2641c497",
        "outputId": "eaef1c84-8690-4fb3-f6ac-84de9ead0ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: {'patients': 1171, 'encounters': 53346, 'observations': 299697, 'conditions': 8376, 'medications': 42989, 'procedures': 34981}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Goes through each of the LOINC and ICD10 codes and normalizes them, by stripping their\n",
        "# ends and uppercasing them.\n",
        "def normalize_loinc(loinc:str):\n",
        "    if pd.isna(loinc):\n",
        "        return None\n",
        "    return str(loinc).strip().upper()\n",
        "\n",
        "def normalize_icd10(code:str):\n",
        "    if pd.isna(code):\n",
        "        return None\n",
        "    return str(code).strip().upper()\n",
        "\n",
        "observations[\"LOINC\"] = observations[\"CODE\"].apply(normalize_loinc)\n",
        "conditions[\"ICD10\"] = conditions[\"CODE\"].apply(normalize_icd10)\n",
        "\n",
        "# Build encounter-level keys for citation anchoring\n",
        "# These keys are going to be unique!\n",
        "def case_id(patient_id, encounter_id):\n",
        "    return f\"{patient_id}_{encounter_id}\"\n",
        "\n",
        "# Applying case ids to each of the tables.\n",
        "encounters[\"case_id\"] = encounters.apply(lambda r: case_id(r[\"PATIENT\"], r[\"Id\"]), axis=1)\n",
        "observations[\"case_id\"] = observations.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "conditions[\"case_id\"] = conditions.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "medications[\"case_id\"] = medications.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "procedures[\"case_id\"] = procedures.apply(lambda r: case_id(r[\"PATIENT\"], r[\"ENCOUNTER\"]), axis=1)\n",
        "\n",
        "# Number of rows in each of the tables.\n",
        "print(\"Rows:\", {\n",
        "    \"patients\": len(patients), \"encounters\": len(encounters),\n",
        "    \"observations\": len(observations), \"conditions\": len(conditions),\n",
        "    \"medications\": len(medications), \"procedures\": len(procedures)\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b55b3f7",
      "metadata": {
        "id": "0b55b3f7"
      },
      "source": [
        "## 5. Minimal Reference Ranges (Demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3341501d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3341501d",
        "outputId": "630e37e7-e6ac-494b-d73e-930685c9c84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: outputs/ref_ranges.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "OUTPUT = Path(\"outputs\")\n",
        "OUTPUT.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "REF_RANGES_FILE = OUTPUT / \"ref_ranges.json\"\n",
        "\n",
        "ref_ranges = {\n",
        "    \"8480-6\": {\"name\": \"Systolic BP\", \"units\": \"mmHg\", \"low\": 90, \"high\": 120},\n",
        "    \"8462-4\": {\"name\": \"Diastolic BP\", \"units\": \"mmHg\", \"low\": 60, \"high\": 80},\n",
        "    \"8867-4\": {\"name\": \"Heart rate\", \"units\": \"bpm\", \"low\": 60, \"high\": 100},\n",
        "    \"8310-5\": {\"name\": \"Body temperature\", \"units\": \"C\", \"low\": 36.1, \"high\": 37.2},\n",
        "    \"9279-1\": {\"name\": \"Respiratory rate\", \"units\": \"breaths/min\", \"low\": 12, \"high\": 20},\n",
        "    \"718-7\":  {\"name\": \"Hemoglobin\", \"units\": \"g/dL\", \"low\": 12, \"high\": 17.5},\n",
        "    \"2160-0\": {\"name\": \"Creatinine\", \"units\": \"mg/dL\", \"low\": 0.6, \"high\": 1.3}\n",
        "}\n",
        "REF_RANGES_FILE.write_text(json.dumps(ref_ranges, indent=2))\n",
        "print(\"Saved:\", REF_RANGES_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9b497b8",
      "metadata": {
        "id": "a9b497b8"
      },
      "source": [
        "## 6. Evidence Snippet Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "368247d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "368247d0",
        "outputId": "f038163b-71b0-40d2-a263-66ccac784a22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text         type  \\\n",
              "0  [obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...  observation   \n",
              "1  [obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...  observation   \n",
              "2  [obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...  observation   \n",
              "3  [obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...  observation   \n",
              "4  [obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...  observation   \n",
              "\n",
              "                                patient                             encounter  \\\n",
              "0  034e9e3b-2def-4559-bb2a-7850888ae060  e88bc3a9-007c-405e-aabc-792a38f4aa2b   \n",
              "1  034e9e3b-2def-4559-bb2a-7850888ae060  e88bc3a9-007c-405e-aabc-792a38f4aa2b   \n",
              "2  034e9e3b-2def-4559-bb2a-7850888ae060  e88bc3a9-007c-405e-aabc-792a38f4aa2b   \n",
              "3  034e9e3b-2def-4559-bb2a-7850888ae060  e88bc3a9-007c-405e-aabc-792a38f4aa2b   \n",
              "4  034e9e3b-2def-4559-bb2a-7850888ae060  e88bc3a9-007c-405e-aabc-792a38f4aa2b   \n",
              "\n",
              "     loinc             timestamp  \\\n",
              "0   8302-2  2012-01-23T17:45:28Z   \n",
              "1  72514-3  2012-01-23T17:45:28Z   \n",
              "2  29463-7  2012-01-23T17:45:28Z   \n",
              "3  39156-5  2012-01-23T17:45:28Z   \n",
              "4   8462-4  2012-01-23T17:45:28Z   \n",
              "\n",
              "                                                meta icd10  code  \n",
              "0  obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...   NaN   NaN  \n",
              "1  obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...   NaN   NaN  \n",
              "2  obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...   NaN   NaN  \n",
              "3  obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...   NaN   NaN  \n",
              "4  obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...   NaN   NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e8cb10d-6150-482a-8cc6-4633c7942b9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>patient</th>\n",
              "      <th>encounter</th>\n",
              "      <th>loinc</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>meta</th>\n",
              "      <th>icd10</th>\n",
              "      <th>code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...</td>\n",
              "      <td>observation</td>\n",
              "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
              "      <td>e88bc3a9-007c-405e-aabc-792a38f4aa2b</td>\n",
              "      <td>8302-2</td>\n",
              "      <td>2012-01-23T17:45:28Z</td>\n",
              "      <td>obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...</td>\n",
              "      <td>observation</td>\n",
              "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
              "      <td>e88bc3a9-007c-405e-aabc-792a38f4aa2b</td>\n",
              "      <td>72514-3</td>\n",
              "      <td>2012-01-23T17:45:28Z</td>\n",
              "      <td>obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...</td>\n",
              "      <td>observation</td>\n",
              "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
              "      <td>e88bc3a9-007c-405e-aabc-792a38f4aa2b</td>\n",
              "      <td>29463-7</td>\n",
              "      <td>2012-01-23T17:45:28Z</td>\n",
              "      <td>obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...</td>\n",
              "      <td>observation</td>\n",
              "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
              "      <td>e88bc3a9-007c-405e-aabc-792a38f4aa2b</td>\n",
              "      <td>39156-5</td>\n",
              "      <td>2012-01-23T17:45:28Z</td>\n",
              "      <td>obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88b...</td>\n",
              "      <td>observation</td>\n",
              "      <td>034e9e3b-2def-4559-bb2a-7850888ae060</td>\n",
              "      <td>e88bc3a9-007c-405e-aabc-792a38f4aa2b</td>\n",
              "      <td>8462-4</td>\n",
              "      <td>2012-01-23T17:45:28Z</td>\n",
              "      <td>obs:034e9e3b-2def-4559-bb2a-7850888ae060:e88bc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e8cb10d-6150-482a-8cc6-4633c7942b9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e8cb10d-6150-482a-8cc6-4633c7942b9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e8cb10d-6150-482a-8cc6-4633c7942b9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-63ee4ed0-baba-460b-a0e4-46e930725004\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63ee4ed0-baba-460b-a0e4-46e930725004')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-63ee4ed0-baba-460b-a0e4-46e930725004 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import json\n",
        "# Essentially we are converting all these structured data into text snippets.\n",
        "# Takes a row from the o  bservation table and creates a snippet for it.\n",
        "def make_obs_snippet(row, ref_ranges_map):\n",
        "    loinc = row.get(\"LOINC\")\n",
        "    value, unit = row.get(\"VALUE\"), row.get(\"UNITS\")\n",
        "    ts = row.get(\"DATE\")\n",
        "    meta = f\"obs:{row['PATIENT']}:{row['ENCOUNTER']}:{loinc}:{ts}\"\n",
        "    interp = None\n",
        "    if loinc in ref_ranges_map and pd.notna(value):\n",
        "        rr = ref_ranges_map[loinc]\n",
        "        try:\n",
        "            v = float(value)\n",
        "            if v < rr[\"low\"]:\n",
        "                interp = \"low\"\n",
        "            elif v > rr[\"high\"]:\n",
        "                interp = \"high\"\n",
        "            else:\n",
        "                interp = \"normal\"\n",
        "        except:\n",
        "            pass\n",
        "    text = f\"[{meta}] LOINC {loinc} value {value} {unit} on {ts}. Interpretation: {interp or 'unknown'}.\"\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"type\": \"observation\",\n",
        "        \"patient\": row[\"PATIENT\"],\n",
        "        \"encounter\": row[\"ENCOUNTER\"],\n",
        "        \"loinc\": loinc,\n",
        "        \"timestamp\": ts,\n",
        "        \"meta\": meta\n",
        "    }\n",
        "\n",
        "# Takes a row from the condition table and makes a snippet for it.\n",
        "def make_condition_snippet(row):\n",
        "    meta = f\"cond:{row['PATIENT']}:{row['ENCOUNTER']}:{row['ICD10']}:{row.get('START','')}\"\n",
        "    text = f\"[{meta}] ICD-10 {row['ICD10']} condition {row.get('DESCRIPTION','')} status {row.get('STATUS','')}.\"\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"type\": \"condition\",\n",
        "        \"patient\": row[\"PATIENT\"],\n",
        "        \"encounter\": row[\"ENCOUNTER\"],\n",
        "        \"icd10\": row[\"ICD10\"],\n",
        "        \"timestamp\": row.get(\"START\",\"\"),\n",
        "        \"meta\": meta\n",
        "    }\n",
        "\n",
        "# Medications table and snippets for that.\n",
        "def make_med_snippet(row):\n",
        "    meta = f\"med:{row['PATIENT']}:{row['ENCOUNTER']}:{row.get('CODE','')}:{row.get('START','')}\"\n",
        "    text = f\"[{meta}] Medication {row.get('DESCRIPTION','')} {row.get('REASONDESCRIPTION','')} dose {row.get('DOSE','')}.\"\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"type\": \"medication\",\n",
        "        \"patient\": row[\"PATIENT\"],\n",
        "        \"encounter\": row[\"ENCOUNTER\"],\n",
        "        \"code\": row.get(\"CODE\",\"\"),\n",
        "        \"timestamp\": row.get(\"START\",\"\"),\n",
        "        \"meta\": meta\n",
        "    }\n",
        "\n",
        "# Build corpus\n",
        "ref_map = json.loads(REF_RANGES_FILE.read_text())\n",
        "snippets = []\n",
        "for _, r in observations.iterrows():\n",
        "    snippets.append(make_obs_snippet(r, ref_map))\n",
        "for _, r in conditions.iterrows():\n",
        "    if pd.notna(r.get(\"ICD10\")):\n",
        "        snippets.append(make_condition_snippet(r))\n",
        "for _, r in medications.iterrows():\n",
        "    snippets.append(make_med_snippet(r))\n",
        "\n",
        "import pandas as pd\n",
        "corpus_df = pd.DataFrame(snippets)\n",
        "corpus_df.head()\n",
        "# Corpus dataframe is a dataframe of all observations, conditions, medications, essentailly a nice way to store all the info.\n",
        "\n",
        "# Why was it built the way it is built?\n",
        "# It is searchable, explainable, citable and a good evidence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd095ecf",
      "metadata": {
        "id": "fd095ecf"
      },
      "source": [
        "## 7. DAPT & LoRA Fine‑tuning (Scaffolding)\n",
        "\n",
        "Up and until this part everything was just zero shot or frozen-model inference.\n",
        "\n",
        "Here only we use the corpus etc and continued pretraining of the Clinical Bert model. This is followed by fine-tuning task heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b48c5804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646,
          "referenced_widgets": [
            "8404242a0dc144cea402fa8e0be934e4",
            "bc5fc33d2aa84d9fb2b864c085e8c1ca",
            "167032204aa24a26968941e91fb6fe53",
            "5051298fd1624010b393570986d3f84b",
            "2d2f0572db6e4006ae784389e684dd93",
            "38dfabea6fee4da492da48cedf11a75d",
            "5ba0d8134cce4fc78b073ca7f72e0d93",
            "7a64ea56c9894ecf8ba0b4dbba473f53",
            "194ad30cd811492180ff8ecbdf09bed3",
            "66fd0bf3681a4d37828085db10f99f9c",
            "eb203dd7d58748fd9fa7226d4cc4d802",
            "4d4ec0b46761400aa7792cd5d98e3448",
            "4eadd50a67c0449486a8ce31ff69ab4e",
            "c7366bec274243dbb4566991043f53dc",
            "b8a49372c07b4c8ebdaf1fa15241a6dc",
            "29a3a3f1cde346b8980c3528e7836b64",
            "67ac5ed415eb44a6b180bedbc08ca379",
            "95465c81fbb4423292a04674fd8771e0",
            "c89e3618518b45f78741da5db3cb8ebf",
            "ebe688e47ce84fb6ba734a447c9a6d84",
            "8447fbc2626a4ccb97501c3cc14ae1e5",
            "2d3992d459be485692e8992e6d32b9d7",
            "1f908627eec9436daa7d2e890c9261b9",
            "9c4bddd2ac1a4a26adc392fc3c6eeec3",
            "a3505939b52f4faa88fd61d946663604",
            "69165a1274654926bf7558427cc1319f",
            "57f1f01233af467eb8591678e9667c17",
            "03c7a39f8e2b46ad924bd993180f169c",
            "a5c6cccf27354faf9fb3c3bc6bcf9851",
            "3fade87c247449519c56473a71c62762",
            "66e81e59366a44498489c04ceff5669c",
            "e2a1b6b9ddb340a6b7824b663521ecca",
            "17ca3dc01b384a3b933321d6346c9526",
            "3e11fc9c859d48ffa609b528d342311f",
            "42c46917088e421ab0880c3fdfb2ba44",
            "10e6f08ca07a4d85b164af2306d09a7e",
            "42d1b4ebb59d4a3fa7b761eb895f48b4",
            "bd891104bf8247e190ce67c080e7a897",
            "c42ae88cd39b4f7481eee9fee53b144d",
            "588a289afdb444799b427764b1ceb3ba",
            "5d0f09661c72414e945419dcd146c606",
            "d3dfea5d610546f296ee3f0d48cf8f19",
            "919a87a778664ab6b632b52cbe68cf1c",
            "a6e3c41fdabe4410863e70ef23141b40",
            "81971c00cada481ba5cea3206b4e7202",
            "90b9eae1e6a04ed3b7def3556b02eb60",
            "b31be0c1b7cd40d89e176c0f2d7e4c8c",
            "69564a74614f45a3848d79d9aef1ec74",
            "10108ff4420a444fa11e65f4046c27d3",
            "4c6635d40c7d4c49b8022fa1251c4d60",
            "89c839b5f34342008a21a53d66c40280",
            "6ce6003a38e04cc99434999c81e57fbc",
            "8dd295e63ec743318a54fada33852b6b",
            "994923280a0747ddb601eccc07c1e749",
            "d3878ba7e96748dab6d19a2cc7a63083"
          ]
        },
        "id": "b48c5804",
        "outputId": "6f36b78a-6c19-44f1-d9e9-6e8ffd89c793"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8404242a0dc144cea402fa8e0be934e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d4ec0b46761400aa7792cd5d98e3448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f908627eec9436daa7d2e890c9261b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e11fc9c859d48ffa609b528d342311f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81971c00cada481ba5cea3206b4e7202"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bitsandbytes.cextension:The 8-bit optimizer is not available on your device, only available on CUDA for now.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   4/2500 00:43 < 15:01:51, 0.05 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2956855797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtok_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mmlm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"ckpts\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"dapt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2329\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     )\n\u001b[1;32m   2671\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4008\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4009\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4011\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4097\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4098\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4099\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4100\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_base_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1280\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1000\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0mlayer_head_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    650\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 557\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 487\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mis_causal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cross_attention\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtgt_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         attn_output = torch.nn.functional.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# This is a scaffold to continue pretraining (DAPT) on generated evidence snippets\n",
        "# and optionally fine-tune task heads. Adjust for your compute and data split.\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from pathlib import Path\n",
        "\n",
        "# Define BASE path (assuming it should be the current working directory or similar)\n",
        "BASE = Path(\".\")\n",
        "\n",
        "evidence_texts = corpus_df[\"text\"].tolist()[:20000]  # subset for demo\n",
        "ds = Dataset.from_dict({\"text\": evidence_texts})\n",
        "tok = AutoTokenizer.from_pretrained(CFG.embed_model)\n",
        "\n",
        "def tok_fn(batch):\n",
        "    return tok(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "tok_ds = ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "mlm_model = AutoModelForMaskedLM.from_pretrained(CFG.embed_model)\n",
        "peft_cfg = LoraConfig(r=CFG.lora_r, lora_alpha=CFG.lora_alpha, lora_dropout=CFG.lora_dropout, target_modules=[\"query\",\"value\",\"key\",\"dense\"])\n",
        "mlm_model = get_peft_model(mlm_model, peft_cfg)\n",
        "\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tok, mlm_probability=0.15)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=str(BASE / \"ckpts\" / \"dapt\"),\n",
        "    per_device_train_batch_size=8,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=50,\n",
        "    save_steps=200,\n",
        "    report_to=[],\n",
        ")\n",
        "trainer = Trainer(model=mlm_model, args=args, train_dataset=tok_ds, data_collator=collator)\n",
        "trainer.train()\n",
        "mlm_model.save_pretrained(BASE / \"ckpts\" / \"dapt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f71582e",
      "metadata": {
        "id": "0f71582e"
      },
      "source": [
        "## 7. Hybrid Retrieval (BM25 + FAISS) with RRF\n",
        "\n",
        "BM25 is keyword based prediction, so it is going to give you answers where exact words match. Excellent for precise queries but misses semantic meaning.\n",
        "\n",
        "FAISS is for semantic similarity matching, it converts queries into high dimensional vectors and using embeddings it finds the closest matches. But it is prone to give highly irrelevant results.\n",
        "\n",
        "A combination of the two is the best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QsI0hDAG10Qk",
      "metadata": {
        "id": "QsI0hDAG10Qk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # should be True\n",
        "print(CFG.device)                 # should be \"cuda\" if available\n",
        "CFG.embed_model = str(BASE / \"ckpts\" / \"dapt\" / \"checkpoint-800\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5b5f50",
      "metadata": {
        "id": "1a5b5f50"
      },
      "outputs": [],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import re\n",
        "\n",
        "# Sample the corpus_df *before* creating the BM25 and FAISS indices\n",
        "# corpus_df = corpus_df.sample(5000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "tok = lambda s: [w for w in re.findall(r\"[A-Za-z0-9_.:-]+\", str(s).lower()) if w not in ENGLISH_STOP_WORDS]\n",
        "bm25 = BM25Okapi(corpus_df[\"text\"].apply(tok).tolist()) # Used to create a embedding that can be used for keyword based retreival.\n",
        "\n",
        "# Dense embeddings (FAISS) setup\n",
        "import numpy as np\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CFG.embed_model)\n",
        "embed_model = AutoModel.from_pretrained(CFG.embed_model)\n",
        "\n",
        "# Commenting out LoRA configuration for the embedding model\n",
        "from peft import LoraConfig, get_peft_model\n",
        "peft_cfg = LoraConfig(r=CFG.lora_r, lora_alpha=CFG.lora_alpha, lora_dropout=CFG.lora_dropout, target_modules=[\"query\",\"value\",\"key\",\"dense\"])\n",
        "embed_model = get_peft_model(embed_model, peft_cfg)\n",
        "\n",
        "\n",
        "def mean_pool(last_hidden_state, attention_mask):\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-9)\n",
        "\n",
        "def encode_texts(texts, batch=64):\n",
        "    from torch import no_grad\n",
        "    import torch\n",
        "    embs = []\n",
        "    for i in range(0, len(texts), batch):\n",
        "        b = texts[i:i+batch]\n",
        "        inputs = tokenizer(b, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "        if CFG.device == \"auto\":\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        else:\n",
        "            device = CFG.device\n",
        "        inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "        embed_model.to(device)\n",
        "        with no_grad():\n",
        "            out = embed_model(**inputs)\n",
        "            pooled = mean_pool(out.last_hidden_state, inputs[\"attention_mask\"])\n",
        "            embs.append(pooled.detach().cpu().numpy().astype(\"float32\"))\n",
        "    return np.vstack(embs)\n",
        "\n",
        "dense_embeddings = encode_texts(corpus_df[\"text\"].tolist(), batch=128)\n",
        "\n",
        "# Add print statements to inspect embeddings\n",
        "print(\"Shape of dense_embeddings:\", dense_embeddings.shape)\n",
        "print(\"Sample of dense_embeddings:\", dense_embeddings[:2])\n",
        "\n",
        "\n",
        "index = faiss.IndexFlatIP(dense_embeddings.shape[1])\n",
        "faiss.normalize_L2(dense_embeddings)\n",
        "index.add(dense_embeddings)\n",
        "\n",
        "def search_hybrid(query, top_k=50, rrf_k=60):\n",
        "    # BM25\n",
        "    bm_scores = bm25.get_scores(tok(query))\n",
        "    bm_top = np.argsort(-bm_scores)[:top_k]\n",
        "    # Dense\n",
        "    q_emb = encode_texts([query])\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    dense_top = I[0]\n",
        "\n",
        "    # RRF\n",
        "    # Rank positions\n",
        "    ranks = {}\n",
        "    for rank, idx in enumerate(bm_top, 1):\n",
        "        ranks.setdefault(idx, {})[\"bm25\"] = rank\n",
        "    for rank, idx in enumerate(dense_top, 1):\n",
        "        ranks.setdefault(idx, {})[\"dense\"] = rank\n",
        "    rrf_scores = {}\n",
        "    for idx, rks in ranks.items():\n",
        "        s = 0.0\n",
        "        if \"bm25\" in rks:  s += 1.0/(rrf_k + rks[\"bm25\"])\n",
        "        if \"dense\" in rks: s += 1.0/(rrf_k + rks[\"dense\"])\n",
        "        rrf_scores[idx] = s\n",
        "    ranked = sorted(rrf_scores.items(), key=lambda x: -x[1])[:top_k]\n",
        "    return [(int(i), float(s)) for i,s in ranked]\n",
        "\n",
        "# Simple cross-encoder rerank (placeholder: adds small weight to dense similarity)\n",
        "def rerank_with_cross_encoder(query, results, alpha=0.1):\n",
        "    # In production: load a clinical cross-encoder and score pairs (query, text).\n",
        "    # Here we nudge by dense proximity proxy carried in rrf score.\n",
        "    return sorted(results, key=lambda x: -x[1])  # already sorted"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faiss.write_index(index, \"faiss_index.index\")"
      ],
      "metadata": {
        "id": "lhJS2RKMOJX9"
      },
      "id": "lhJS2RKMOJX9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"bm25_index.pkl\", \"wb\") as f:\n",
        "  pickle.dump(bm25, f)"
      ],
      "metadata": {
        "id": "wgBuDWrwOz5D"
      },
      "id": "wgBuDWrwOz5D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "rdASus9ux7dD",
      "metadata": {
        "id": "rdASus9ux7dD"
      },
      "source": [
        "Till here Retreival part was implemented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57b30f98",
      "metadata": {
        "id": "57b30f98"
      },
      "source": [
        "## 8. MCP Tools (EHR & Clinical Calculators)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5025cef6",
      "metadata": {
        "id": "5025cef6"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field, ValidationError\n",
        "from typing import List, Optional, Literal, Dict, Any\n",
        "from datetime import datetime\n",
        "import math, logging, uuid\n",
        "\n",
        "# In this section we build schema validated tools/functions which the agents can call to\n",
        "# Access EHR data, Run clinical calculators, and audit all the usage of tokens\n",
        "LOGS = \"log\"\n",
        "logging.basicConfig(filename=str(f\"{LOGS} / audit.log\"), level=logging.INFO)\n",
        "\n",
        "class SearchEvidenceRequest(BaseModel):\n",
        "    patient_id: Optional[str] = None\n",
        "    query: str\n",
        "    data_types: Optional[List[Literal[\"observation\",\"condition\",\"medication\"]]] = None\n",
        "    top_k: int = 20\n",
        "\n",
        "class LabRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    loinc_codes: Optional[List[str]] = None\n",
        "    hours_back: Optional[int] = None\n",
        "\n",
        "class VitalsRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    vital_types: Optional[List[str]] = None\n",
        "    hours_back: Optional[int] = None\n",
        "\n",
        "class ConditionsRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    active_only: bool = True\n",
        "\n",
        "class MedsRequest(BaseModel):\n",
        "    patient_id: str\n",
        "    encounter_id: Optional[str] = None\n",
        "\n",
        "# Logs every tool call\n",
        "def audit(event:str, payload:Dict[str,Any]):\n",
        "    logging.info(json.dumps({\n",
        "        \"ts\": datetime.utcnow().isoformat(),\n",
        "        \"event\": event,\n",
        "        \"payload\": payload\n",
        "    }))\n",
        "\n",
        "# EHR search\n",
        "#\n",
        "def ehr_search_evidence(req: SearchEvidenceRequest):\n",
        "    try:\n",
        "        req = SearchEvidenceRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "\n",
        "    # Perform hy  brid search to get initial results\n",
        "    # Increase top_k to retrieve a larger set before filtering by patient_id\n",
        "    initial_results = rerank_with_cross_encoder(req.query, search_hybrid(req.query, top_k=200))\n",
        "\n",
        "    hits = []\n",
        "    for idx, score in initial_results:\n",
        "        row = corpus_df.iloc[idx]\n",
        "        # Apply patient_id and data_types filtering after initial search\n",
        "        if req.patient_id and row[\"patient\"] != req.patient_id:\n",
        "            continue\n",
        "        if req.data_types and row[\"type\"] not in req.data_types:\n",
        "            continue\n",
        "        hits.append({\"text\": row[\"text\"], \"meta\": row[\"meta\"], \"score\": score, \"type\": row[\"type\"]})\n",
        "\n",
        "    # Limit the final number of hits\n",
        "    hits = hits[:req.top_k]\n",
        "\n",
        "    audit(\"ehr.search_evidence\", {\"query\": req.query, \"n\": len(hits)})\n",
        "    return hits\n",
        "\n",
        "\n",
        "def ehr_get_labs(req: LabRequest):\n",
        "    try:\n",
        "        req = LabRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    df = observations[observations[\"PATIENT\"] == req.patient_id]\n",
        "    if req.loinc_codes:\n",
        "        df = df[df[\"LOINC\"].isin(req.loinc_codes)]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "def ehr_get_vitals(req: VitalsRequest):\n",
        "    try:\n",
        "        req = VitalsRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    vital_codes = [\"8480-6\",\"8462-4\",\"8867-4\",\"8310-5\",\"9279-1\"]\n",
        "    df = observations[(observations[\"PATIENT\"] == req.patient_id) & (observations[\"LOINC\"].isin(vital_codes))]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "def ehr_get_conditions(req: ConditionsRequest):\n",
        "    try:\n",
        "        req = ConditionsRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    df = conditions[conditions[\"PATIENT\"] == req.patient_id]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "def ehr_get_medications(req: MedsRequest):\n",
        "    try:\n",
        "        req = MedsRequest(**req if isinstance(req, dict) else req.model_dump())\n",
        "    except ValidationError as e:\n",
        "        raise ValueError(str(e))\n",
        "    df = medications[medications[\"PATIENT\"] == req.patient_id]\n",
        "    if req.encounter_id:\n",
        "        df = df[df[\"ENCOUNTER\"] == req.encounter_id]\n",
        "    return df.to_dict(orient=\"records\")\n",
        "\n",
        "# Clinical calculators\n",
        "def calc_qsofa(respiratory_rate, systolic_bp, gcs_score):\n",
        "    score = 0\n",
        "    score += 1 if respiratory_rate is not None and respiratory_rate >= 22 else 0\n",
        "    score += 1 if systolic_bp is not None and systolic_bp <= 100 else 0\n",
        "    score += 1 if gcs_score is not None and gcs_score < 15 else 0\n",
        "    return {\"qSOFA\": score}\n",
        "\n",
        "def calc_egfr(creatinine, age, sex, race=\"non-black\"):\n",
        "    # CKD-EPI 2009 (simplified; for demo only)\n",
        "    kappa = 0.7 if sex.lower().startswith(\"f\") else 0.9\n",
        "    alpha = -0.329 if sex.lower().startswith(\"f\") else -0.411\n",
        "    min_scr = min(creatinine/kappa, 1)\n",
        "    max_scr = max(creatinine/kappa, 1)\n",
        "    egfr = 141 * (min_scr**alpha) * (max_scr**(-1.209)) * (0.993**age)\n",
        "    if sex.lower().startswith(\"f\"): egfr *= 1.018\n",
        "    if race.lower() == \"black\": egfr *= 1.159\n",
        "    return {\"eGFR\": egfr}\n",
        "\n",
        "def calc_lab_interpretation(code, value, units, age=None, sex=None):\n",
        "    rm = json.loads(REF_RANGES_FILE.read_text())\n",
        "    status = \"unknown\"\n",
        "    if code in rm:\n",
        "        low, high = rm[code][\"low\"], rm[code][\"high\"]\n",
        "        try:\n",
        "            v = float(value)\n",
        "            status = \"low\" if v < low else (\"high\" if v > high else \"normal\")\n",
        "        except:\n",
        "            status = \"unknown\"\n",
        "    return {\"interpretation\": status}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01726381",
      "metadata": {
        "id": "01726381"
      },
      "source": [
        "## 9. Agents (Clinical QA, Triage, Diagnosis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de29d438",
      "metadata": {
        "id": "de29d438"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load BioGPT model (causal LM)\n",
        "biogpt_model_name = \"microsoft/BioGPT-Large\"\n",
        "biogpt_tokenizer = AutoTokenizer.from_pretrained(biogpt_model_name)\n",
        "biogpt_model = AutoModelForCausalLM.from_pretrained(\n",
        "    biogpt_model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# WE are using local models instead of APIs for ease of reproducibility\n",
        "class ClinicalQAAgentRAG:\n",
        "    def answer(self, patient_id:str, question:str, triage_flags: List[Dict[str, Any]], top_k:int=5, max_new_tokens:int=200):\n",
        "        # 1) Retrieve top-k evidence\n",
        "        # Construct a more specific query based on triage flags if available\n",
        "        if triage_flags:\n",
        "            flag_queries = [f\"{flag['interpretation']} {flag['test_code']}\" for flag in triage_flags]\n",
        "            # Combine original question with flag information for a more targeted query\n",
        "            targeted_query = f\"{question} based on abnormal findings: {', '.join(flag_queries)}\"\n",
        "        else:\n",
        "            targeted_query = question\n",
        "\n",
        "        hits = ehr_search_evidence({\"patient_id\": patient_id, \"query\": targeted_query, \"top_k\": top_k})\n",
        "        top_snippets = hits[:top_k]\n",
        "\n",
        "        # 2) Build prompt for BioGPT\n",
        "        evidence_text = \"\\n\".join([f\"- {h['text']}\" for h in top_snippets])\n",
        "        print(evidence_text)\n",
        "        prompt = (\n",
        "            f\"Question: {question}\\n\\n\"\n",
        "            f\"Patient evidence:\\n{evidence_text}\\n\\n\"\n",
        "            f\"Answer the question using only the evidence above. \"\n",
        "            f\"Include the citation meta IDs (inside brackets, e.g., [obs:...]).\\n\\n\"\n",
        "            f\"Answer:\"\n",
        "        )\n",
        "\n",
        "        # 3) Generate with BioGPT\n",
        "        inputs = biogpt_tokenizer(prompt, return_tensors=\"pt\").to(biogpt_model.device)\n",
        "        outputs = biogpt_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        answer = biogpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # 4) Package results\n",
        "        citations = [h[\"meta\"] for h in top_snippets]\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"citations\": citations,\n",
        "            \"hits\": top_snippets\n",
        "        }\n",
        "\n",
        "class TriageAgent:\n",
        "    def analyze(self, patient_id:str):\n",
        "        labs = ehr_get_labs({\"patient_id\": patient_id})\n",
        "        vitals = ehr_get_vitals({\"patient_id\": patient_id})\n",
        "        flags = []\n",
        "        for row in labs + vitals:\n",
        "            code = row.get(\"LOINC\")\n",
        "            val = row.get(\"VALUE\")\n",
        "            units = row.get(\"UNITS\")\n",
        "            interp = calc_lab_interpretation(code, val, units)\n",
        "            if interp[\"interpretation\"] in {\"low\",\"high\"}:\n",
        "                flags.append({\n",
        "                    \"test_code\": code, \"value\": val, \"interpretation\": interp[\"interpretation\"],\n",
        "                    \"abnormal\": True, \"meta\": f\"obs:{row['PATIENT']}:{row['ENCOUNTER']}:{code}:{row.get('DATE','')}\"\n",
        "                })\n",
        "        # qSOFA demo: fetch last vitals\n",
        "        def last_value(code):\n",
        "            rows = [r for r in vitals if r.get(\"LOINC\")==code and pd.notna(r.get(\"VALUE\"))]\n",
        "            if not rows: return None\n",
        "            try: return float(rows[-1][\"VALUE\"])\n",
        "            except: return None\n",
        "        rr = last_value(\"9279-1\")\n",
        "        sbp = last_value(\"8480-6\")\n",
        "        gcs = 15  # Synthea lacks GCS; assume normal for demo\n",
        "        qsofa = calc_qsofa(rr, sbp, gcs)\n",
        "        # qSOFA is a score that indicates risk.\n",
        "        return {\"flags\": flags, \"scores\": {\"qSOFA\": qsofa[\"qSOFA\"]}}\n",
        "\n",
        "class DiagnosisAgent:\n",
        "    def predict(self, patient_id:str):\n",
        "        # Heuristic placeholder: collect active conditions and propose common ICD10 codes\n",
        "        conds = ehr_get_conditions({\"patient_id\": patient_id})\n",
        "        preds = list({c.get(\"ICD10\") for c in conds if c.get(\"ICD10\")})[:3]\n",
        "        confidences = [0.7 if i==0 else 0.5 for i in range(len(preds))]\n",
        "        evidence = [f\"cond:{c['PATIENT']}:{c['ENCOUNTER']}:{c.get('ICD10')}:{c.get('START','')}\" for c in conds[:5]]\n",
        "        return {\"predictions\": preds, \"confidences\": confidences, \"evidence\": evidence}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d40e1071",
      "metadata": {
        "id": "d40e1071"
      },
      "source": [
        "## 10. Orchestration (QA → Triage → Diagnosis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dfb77e",
      "metadata": {
        "id": "03dfb77e"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "# An Orchestrator is the controller of the multi agents, it calls the agents in the right order passes the right data and assembles the results in the right order. Used to\n",
        "# \"stich\" the agents in one pipeline.\n",
        "\n",
        "class Orchestrator:\n",
        "    def __init__(self):\n",
        "        self.qa = ClinicalQAAgentRAG()\n",
        "        self.triage = TriageAgent()\n",
        "        self.dx = DiagnosisAgent()\n",
        "\n",
        "    def run_case(self, patient_id:str, encounter_id:str=None, question:str=\"What are the key issues?\"):\n",
        "        case = encounter_id or f\"any\"\n",
        "        case_id = f\"{patient_id}_{case}\"\n",
        "        triage_out = self.triage.analyze(patient_id)\n",
        "        # Pass triage_flags to the QA agent\n",
        "        qa_out = self.qa.answer(patient_id, question, triage_flags=triage_out[\"flags\"])\n",
        "        dx_out = self.dx.predict(patient_id)\n",
        "\n",
        "        # Structured synthesis\n",
        "        report = {\n",
        "            \"case_id\": case_id,\n",
        "            \"question\": question,\n",
        "            \"qa\": qa_out,\n",
        "            \"triage\": triage_out,\n",
        "            \"diagnosis\": dx_out\n",
        "        }\n",
        "        return report\n",
        "\n",
        "orch = Orchestrator()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c0dace5",
      "metadata": {
        "id": "3c0dace5"
      },
      "source": [
        "## 11. Evaluation & Required JSONL Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe9ac2e",
      "metadata": {
        "id": "7fe9ac2e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import jsonlines\n",
        "\n",
        "def write_required_outputs(report, output_dir=OUTPUT):\n",
        "    output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # retrieval_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"retrieval_results.jsonl\", \"w\") as w:\n",
        "        for i, h in enumerate(report[\"qa\"][\"hits\"][:50]):\n",
        "            w.write({\n",
        "                \"query_id\": f\"Q001\",\n",
        "                \"patient_id\": report[\"case_id\"].split(\"_\")[0],\n",
        "                \"snippets\": [h[\"text\"]],\n",
        "                \"scores\": [h[\"score\"]]\n",
        "            })\n",
        "\n",
        "    # qa_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"qa_results.jsonl\", \"w\") as w:\n",
        "        w.write({\n",
        "            \"case_id\": report[\"case_id\"],\n",
        "            \"question\": report[\"question\"],\n",
        "            \"answer\": report[\"qa\"][\"answer\"],\n",
        "            \"citations\": report[\"qa\"][\"citations\"]\n",
        "        })\n",
        "\n",
        "    # triage_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"triage_results.jsonl\", \"w\") as w:\n",
        "        for flag in report[\"triage\"][\"flags\"]:\n",
        "            w.write({\n",
        "                \"case_id\": report[\"case_id\"],\n",
        "                \"test_code\": flag[\"test_code\"],\n",
        "                \"value\": flag[\"value\"],\n",
        "                \"interpretation\": flag[\"interpretation\"],\n",
        "                \"abnormal\": flag[\"abnormal\"]\n",
        "            })\n",
        "\n",
        "    # diagnosis_results.jsonl\n",
        "    with jsonlines.open(output_dir / \"diagnosis_results.jsonl\", \"w\") as w:\n",
        "        w.write({\n",
        "            \"case_id\": report[\"case_id\"],\n",
        "            \"predictions\": report[\"diagnosis\"][\"predictions\"],\n",
        "            \"confidences\": report[\"diagnosis\"][\"confidences\"],\n",
        "            \"evidence\": report[\"diagnosis\"][\"evidence\"]\n",
        "        })\n",
        "\n",
        "    # system_metrics.json (placeholder)\n",
        "    metrics = {\n",
        "        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        \"n_evidence\": len(report[\"qa\"][\"hits\"]),\n",
        "        \"n_flags\": len(report[\"triage\"][\"flags\"]),\n",
        "        \"qSOFA\": report[\"triage\"][\"scores\"][\"qSOFA\"]\n",
        "    }\n",
        "    (output_dir / \"system_metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
        "    return [str(p) for p in (output_dir.iterdir()) if p.is_file()]\n",
        "\n",
        "# Demo run on the first patient\n",
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "report = orch.run_case(demo_patient, question=\"Possible causes of abnormal vitals and labs?\")\n",
        "files = write_required_outputs(report)\n",
        "print(report)\n",
        "files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9649505",
      "metadata": {
        "id": "a9649505"
      },
      "outputs": [],
      "source": [
        "# Find a patient with abnormal observations\n",
        "abnormal_observations = observations[observations['LOINC'].isin(ref_map.keys())]\n",
        "\n",
        "# Filter for observations outside the normal range\n",
        "def is_abnormal(row):\n",
        "    loinc = row.get(\"LOINC\")\n",
        "    value = row.get(\"VALUE\")\n",
        "    if loinc in ref_map and pd.notna(value):\n",
        "        rr = ref_map[loinc]\n",
        "        try:\n",
        "            v = float(value)\n",
        "            if v < rr[\"low\"] or v > rr[\"high\"]:\n",
        "                return True\n",
        "        except:\n",
        "            pass\n",
        "    return False\n",
        "\n",
        "abnormal_patients_df = abnormal_observations[abnormal_observations.apply(is_abnormal, axis=1)]\n",
        "\n",
        "if not abnormal_patients_df.empty:\n",
        "    new_demo_patient = abnormal_patients_df.iloc[0][\"PATIENT\"]\n",
        "    print(f\"Found a patient with abnormal observations: {new_demo_patient}\")\n",
        "    # Now run the orchestrator with the new patient ID\n",
        "    report = orch.run_case(new_demo_patient, question=\"What is the diagnosis inferred from vitals and labs?\")\n",
        "    files = write_required_outputs(report)\n",
        "    print(report)\n",
        "    display(files)\n",
        "else:\n",
        "    print(\"No patients with abnormal observations found in the corpus.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e85a62",
      "metadata": {
        "id": "06e85a62"
      },
      "outputs": [],
      "source": [
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "search_results = ehr_search_evidence({\"patient_id\": demo_patient, \"query\": \"Possible causes of abnormal vitals and labs?\", \"top_k\": 20})\n",
        "print(search_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b0634ff",
      "metadata": {
        "id": "4b0634ff"
      },
      "outputs": [],
      "source": [
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "search_results = ehr_search_evidence({\"patient_id\": demo_patient, \"query\": \"patient's blood pressure\", \"top_k\": 20})\n",
        "print(search_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cbd454",
      "metadata": {
        "id": "91cbd454"
      },
      "source": [
        "## 13. Safety, Validation & Disclaimers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9ce6ba",
      "metadata": {
        "id": "1c9ce6ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "def validate_inputs_or_raise(patient_id:str):\n",
        "    assert isinstance(patient_id, str) and len(patient_id)>0, \"Invalid patient_id\"\n",
        "\n",
        "def human_in_the_loop_required(conf: float, threshold: float = 0.8) -> bool:\n",
        "    return conf < threshold\n",
        "\n",
        "print(\"Safety helpers ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "395546f3",
      "metadata": {
        "id": "395546f3"
      },
      "source": [
        "## 14. Quickstart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d6f689",
      "metadata": {
        "id": "29d6f689"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\"\"\n",
        "1) Run Section 1 to install dependencies (if needed).\n",
        "2) Run Sections 2–6 to prepare data & evidence corpus.\n",
        "3) Run Section 7 to build hybrid indices.\n",
        "4) Run Sections 8–11 to enable MCP tools, agents, orchestration, and outputs.\n",
        "5) (Optional) Run Section 12 to experiment with DAPT/LoRA.\n",
        "Outputs are written to ./outputs in the required JSONL/JSON formats.\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feb5147e"
      },
      "source": [
        "# Final Testing and Analysis Cell\n",
        "\n",
        "import time\n",
        "import random\n",
        "import jsonlines\n",
        "from pathlib import Path\n",
        "\n",
        "# Define an output directory for this final test run\n",
        "TEST_OUTPUT_DIR = Path(\"test_outputs\")\n",
        "TEST_OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# --- Performance Analysis ---\n",
        "print(\"--- Performance Analysis ---\")\n",
        "num_runs = 10  # Number of times to run the orchestrator for performance testing\n",
        "total_time = 0\n",
        "\n",
        "# Get a list of patient IDs to use for testing\n",
        "test_patient_ids = patients[\"Id\"].tolist()\n",
        "if len(test_patient_ids) > num_runs:\n",
        "    test_patient_ids = random.sample(test_patient_ids, num_runs)\n",
        "else:\n",
        "    num_runs = len(test_patient_ids) # Adjust num_runs if fewer patients than requested\n",
        "\n",
        "for i in range(num_runs):\n",
        "    patient_id = test_patient_ids[i]\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        report = orch.run_case(patient_id, question=\"What are the main health concerns for this patient?\")\n",
        "        # Optionally write outputs for each run if needed for later analysis\n",
        "        # write_required_outputs(report, output_dir=TEST_OUTPUT_DIR / f\"run_{i}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during performance run {i} for patient {patient_id}: {e}\")\n",
        "        continue\n",
        "    end_time = time.time()\n",
        "    run_time = end_time - start_time\n",
        "    total_time += run_time\n",
        "    print(f\"Run {i+1} for patient {patient_id} took {run_time:.2f} seconds\")\n",
        "\n",
        "average_time = total_time / num_runs if num_runs > 0 else 0\n",
        "print(f\"\\nAverage time per case: {average_time:.2f} seconds\")\n",
        "\n",
        "# --- Error Case Testing ---\n",
        "print(\"\\n--- Error Case Testing ---\")\n",
        "\n",
        "# Test with an invalid patient ID\n",
        "print(\"\\nTesting with invalid patient ID:\")\n",
        "invalid_patient_id = \"invalid-patient-id-123\"\n",
        "try:\n",
        "    report = orch.run_case(invalid_patient_id, question=\"Should not work\")\n",
        "    print(\"Unexpected success with invalid patient ID.\")\n",
        "except Exception as e:\n",
        "    print(f\"Caught expected error for invalid patient ID: {e}\")\n",
        "\n",
        "# Test with an empty question\n",
        "print(\"\\nTesting with empty question:\")\n",
        "demo_patient = patients.iloc[0][\"Id\"]\n",
        "try:\n",
        "    report = orch.run_case(demo_patient, question=\"\")\n",
        "    print(\"Result for empty question:\", report[\"qa\"][\"answer\"])\n",
        "except Exception as e:\n",
        "    print(f\"Caught error for empty question: {e}\")\n",
        "\n",
        "\n",
        "# --- Ablation Studies (Conceptual - requires code modification) ---\n",
        "print(\"\\n--- Ablation Studies (Conceptual) ---\")\n",
        "print(\"Ablation studies would typically involve modifying the Orchestrator or agents\")\n",
        "print(\"to remove specific components (e.g., hybrid retrieval, RRF, specific tools)\")\n",
        "print(\"and then re-running the same test cases to compare performance.\")\n",
        "print(\"This requires code changes outside of this test cell.\")\n",
        "print(\"\\nFor example, to test the impact of hybrid retrieval, you would modify\")\n",
        "print(\"ehr_search_evidence to use *only* BM25 or *only* dense retrieval.\")\n",
        "print(\"Then, run the performance analysis again and compare results.\")\n",
        "\n",
        "# Example of how you *might* simulate an ablation (this requires modifying the orch instance)\n",
        "# Note: This is just illustrative. A proper ablation study would involve code changes elsewhere.\n",
        "# print(\"\\nIllustrative example: Simulating removing hybrid retrieval (requires code change)\")\n",
        "# original_search_fn = ehr_search_evidence\n",
        "# def simple_search_ablation(req: SearchEvidenceRequest):\n",
        "#     # Simulate only dense search (conceptual)\n",
        "#     print(\"Using simulated simple search (ablation)\")\n",
        "#     q_emb = encode_texts([req.query])\n",
        "#     faiss.normalize_L2(q_emb)\n",
        "#     D, I = index.search(q_emb, req.top_k)\n",
        "#     hits = []\n",
        "#     for i, score in zip(I[0], D[0]):\n",
        "#         row = corpus_df.iloc[i]\n",
        "#         if req.patient_id and row[\"patient\"] != req.patient_id:\n",
        "#              continue\n",
        "#         if req.data_types and row[\"type\"] not in req.data_types:\n",
        "#              continue\n",
        "#         hits.append({\"text\": row[\"text\"], \"meta\": row[\"meta\"], \"score\": float(score), \"type\": row[\"type\"]}) # Convert score to float\n",
        "#     return hits[:req.top_k]\n",
        "\n",
        "# # Temporarily replace the search function (requires direct modification of the module or class)\n",
        "# # This is complex and not recommended in a simple test cell.\n",
        "# # Instead, modify the Orchestrator class or the ehr_search_evidence function directly\n",
        "# # for a proper ablation study.\n",
        "# # orch.qa.ehr_search_evidence = simple_search_ablation # This line won't work directly\n",
        "\n",
        "print(\"\\nFinal testing complete.\")"
      ],
      "id": "feb5147e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8404242a0dc144cea402fa8e0be934e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc5fc33d2aa84d9fb2b864c085e8c1ca",
              "IPY_MODEL_167032204aa24a26968941e91fb6fe53",
              "IPY_MODEL_5051298fd1624010b393570986d3f84b"
            ],
            "layout": "IPY_MODEL_2d2f0572db6e4006ae784389e684dd93"
          }
        },
        "bc5fc33d2aa84d9fb2b864c085e8c1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38dfabea6fee4da492da48cedf11a75d",
            "placeholder": "​",
            "style": "IPY_MODEL_5ba0d8134cce4fc78b073ca7f72e0d93",
            "value": "config.json: 100%"
          }
        },
        "167032204aa24a26968941e91fb6fe53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a64ea56c9894ecf8ba0b4dbba473f53",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_194ad30cd811492180ff8ecbdf09bed3",
            "value": 385
          }
        },
        "5051298fd1624010b393570986d3f84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66fd0bf3681a4d37828085db10f99f9c",
            "placeholder": "​",
            "style": "IPY_MODEL_eb203dd7d58748fd9fa7226d4cc4d802",
            "value": " 385/385 [00:00&lt;00:00, 35.9kB/s]"
          }
        },
        "2d2f0572db6e4006ae784389e684dd93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38dfabea6fee4da492da48cedf11a75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba0d8134cce4fc78b073ca7f72e0d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a64ea56c9894ecf8ba0b4dbba473f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194ad30cd811492180ff8ecbdf09bed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66fd0bf3681a4d37828085db10f99f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb203dd7d58748fd9fa7226d4cc4d802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d4ec0b46761400aa7792cd5d98e3448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eadd50a67c0449486a8ce31ff69ab4e",
              "IPY_MODEL_c7366bec274243dbb4566991043f53dc",
              "IPY_MODEL_b8a49372c07b4c8ebdaf1fa15241a6dc"
            ],
            "layout": "IPY_MODEL_29a3a3f1cde346b8980c3528e7836b64"
          }
        },
        "4eadd50a67c0449486a8ce31ff69ab4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ac5ed415eb44a6b180bedbc08ca379",
            "placeholder": "​",
            "style": "IPY_MODEL_95465c81fbb4423292a04674fd8771e0",
            "value": "vocab.txt: "
          }
        },
        "c7366bec274243dbb4566991043f53dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89e3618518b45f78741da5db3cb8ebf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebe688e47ce84fb6ba734a447c9a6d84",
            "value": 1
          }
        },
        "b8a49372c07b4c8ebdaf1fa15241a6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8447fbc2626a4ccb97501c3cc14ae1e5",
            "placeholder": "​",
            "style": "IPY_MODEL_2d3992d459be485692e8992e6d32b9d7",
            "value": " 213k/? [00:00&lt;00:00, 11.9MB/s]"
          }
        },
        "29a3a3f1cde346b8980c3528e7836b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ac5ed415eb44a6b180bedbc08ca379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95465c81fbb4423292a04674fd8771e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c89e3618518b45f78741da5db3cb8ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ebe688e47ce84fb6ba734a447c9a6d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8447fbc2626a4ccb97501c3cc14ae1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3992d459be485692e8992e6d32b9d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f908627eec9436daa7d2e890c9261b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c4bddd2ac1a4a26adc392fc3c6eeec3",
              "IPY_MODEL_a3505939b52f4faa88fd61d946663604",
              "IPY_MODEL_69165a1274654926bf7558427cc1319f"
            ],
            "layout": "IPY_MODEL_57f1f01233af467eb8591678e9667c17"
          }
        },
        "9c4bddd2ac1a4a26adc392fc3c6eeec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c7a39f8e2b46ad924bd993180f169c",
            "placeholder": "​",
            "style": "IPY_MODEL_a5c6cccf27354faf9fb3c3bc6bcf9851",
            "value": "Map: 100%"
          }
        },
        "a3505939b52f4faa88fd61d946663604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fade87c247449519c56473a71c62762",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66e81e59366a44498489c04ceff5669c",
            "value": 20000
          }
        },
        "69165a1274654926bf7558427cc1319f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2a1b6b9ddb340a6b7824b663521ecca",
            "placeholder": "​",
            "style": "IPY_MODEL_17ca3dc01b384a3b933321d6346c9526",
            "value": " 20000/20000 [00:07&lt;00:00, 2655.37 examples/s]"
          }
        },
        "57f1f01233af467eb8591678e9667c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c7a39f8e2b46ad924bd993180f169c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c6cccf27354faf9fb3c3bc6bcf9851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fade87c247449519c56473a71c62762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e81e59366a44498489c04ceff5669c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2a1b6b9ddb340a6b7824b663521ecca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ca3dc01b384a3b933321d6346c9526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e11fc9c859d48ffa609b528d342311f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42c46917088e421ab0880c3fdfb2ba44",
              "IPY_MODEL_10e6f08ca07a4d85b164af2306d09a7e",
              "IPY_MODEL_42d1b4ebb59d4a3fa7b761eb895f48b4"
            ],
            "layout": "IPY_MODEL_bd891104bf8247e190ce67c080e7a897"
          }
        },
        "42c46917088e421ab0880c3fdfb2ba44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42ae88cd39b4f7481eee9fee53b144d",
            "placeholder": "​",
            "style": "IPY_MODEL_588a289afdb444799b427764b1ceb3ba",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "10e6f08ca07a4d85b164af2306d09a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d0f09661c72414e945419dcd146c606",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3dfea5d610546f296ee3f0d48cf8f19",
            "value": 435778770
          }
        },
        "42d1b4ebb59d4a3fa7b761eb895f48b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919a87a778664ab6b632b52cbe68cf1c",
            "placeholder": "​",
            "style": "IPY_MODEL_a6e3c41fdabe4410863e70ef23141b40",
            "value": " 436M/436M [00:01&lt;00:00, 251MB/s]"
          }
        },
        "bd891104bf8247e190ce67c080e7a897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42ae88cd39b4f7481eee9fee53b144d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588a289afdb444799b427764b1ceb3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d0f09661c72414e945419dcd146c606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3dfea5d610546f296ee3f0d48cf8f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "919a87a778664ab6b632b52cbe68cf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6e3c41fdabe4410863e70ef23141b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81971c00cada481ba5cea3206b4e7202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90b9eae1e6a04ed3b7def3556b02eb60",
              "IPY_MODEL_b31be0c1b7cd40d89e176c0f2d7e4c8c",
              "IPY_MODEL_69564a74614f45a3848d79d9aef1ec74"
            ],
            "layout": "IPY_MODEL_10108ff4420a444fa11e65f4046c27d3"
          }
        },
        "90b9eae1e6a04ed3b7def3556b02eb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c6635d40c7d4c49b8022fa1251c4d60",
            "placeholder": "​",
            "style": "IPY_MODEL_89c839b5f34342008a21a53d66c40280",
            "value": "model.safetensors: 100%"
          }
        },
        "b31be0c1b7cd40d89e176c0f2d7e4c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce6003a38e04cc99434999c81e57fbc",
            "max": 435755888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dd295e63ec743318a54fada33852b6b",
            "value": 435755888
          }
        },
        "69564a74614f45a3848d79d9aef1ec74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_994923280a0747ddb601eccc07c1e749",
            "placeholder": "​",
            "style": "IPY_MODEL_d3878ba7e96748dab6d19a2cc7a63083",
            "value": " 436M/436M [00:05&lt;00:00, 92.7MB/s]"
          }
        },
        "10108ff4420a444fa11e65f4046c27d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c6635d40c7d4c49b8022fa1251c4d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89c839b5f34342008a21a53d66c40280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ce6003a38e04cc99434999c81e57fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd295e63ec743318a54fada33852b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "994923280a0747ddb601eccc07c1e749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3878ba7e96748dab6d19a2cc7a63083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}